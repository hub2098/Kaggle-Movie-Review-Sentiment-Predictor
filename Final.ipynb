{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Final Project Data #######################\n",
    "##################### Ken Hubbard ############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n  This program shell reads phrase data for the kaggle phrase sentiment classification problem.\\n  The input to the program is the path to the kaggle directory \"corpus\" and a limit number.\\n  The program reads all of the kaggle phrases, and then picks a random selection of the limit number.\\n  It creates a \"phrasedocs\" variable with a list of phrases consisting of a pair\\n    with the list of tokenized words from the phrase and the label number from 1 to 4\\n  It prints a few example phrases.\\n  In comments, it is shown how to get word lists from the two sentiment lexicons:\\n      subjectivity and LIWC, if you want to use them in your features\\n  Your task is to generate features sets and train and test a classifier.\\n\\n  Usage:  python classifyKaggle.py  <corpus directory path> <limit number>\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "  This program shell reads phrase data for the kaggle phrase sentiment classification problem.\n",
    "  The input to the program is the path to the kaggle directory \"corpus\" and a limit number.\n",
    "  The program reads all of the kaggle phrases, and then picks a random selection of the limit number.\n",
    "  It creates a \"phrasedocs\" variable with a list of phrases consisting of a pair\n",
    "    with the list of tokenized words from the phrase and the label number from 1 to 4\n",
    "  It prints a few example phrases.\n",
    "  In comments, it is shown how to get word lists from the two sentiment lexicons:\n",
    "      subjectivity and LIWC, if you want to use them in your features\n",
    "  Your task is to generate features sets and train and test a classifier.\n",
    "\n",
    "  Usage:  python classifyKaggle.py  <corpus directory path> <limit number>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open python and nltk packages needed for processing\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### TESTING, WORK FROM PROCESSKAGGLE DEFINITION ###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "  limitStr = 10000\n",
    "\n",
    "  limit = int(limitStr)\n",
    "  \n",
    "\n",
    "  \n",
    "  f = open('./train.tsv', 'r')\n",
    "  # loop over lines in the file and use the first limit of them\n",
    "  phrasedata = []\n",
    "  for line in f:\n",
    "    # ignore the first line starting with Phrase and read all lines\n",
    "    if (not line.startswith('Phrase')):\n",
    "      # remove final end of line character\n",
    "      line = line.strip()\n",
    "      # each line has 4 items separated by tabs\n",
    "      # ignore the phrase and sentence ids, and keep the phrase and sentiment\n",
    "      phrasedata.append(line.split('\\t')[2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 156060 phrases, using 10000 random phrases\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "  # pick a random sample of length limit because of phrase overlapping sequences\n",
    "  random.shuffle(phrasedata)\n",
    "  phraselist = phrasedata[:limit]\n",
    "\n",
    "  print('Read', len(phrasedata), 'phrases, using', len(phraselist), 'random phrases')\n",
    "  \n",
    "  # create list of phrase documents as (list of words, label)\n",
    "  phrasedocs = []\n",
    "  # add all the phrases\n",
    "\n",
    "  # each phrase has a list of tokens and the sentiment label (from 0 to 4)\n",
    "  ### bin to only 3 categories for better performance\n",
    "  for phrase in phraselist:\n",
    "    tokens = nltk.word_tokenize(phrase[0])\n",
    "    phrasedocs.append((tokens, int(phrase[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['the', 'bones', 'of', 'queen', 'of', 'the', 'damned'], 3)\n",
      "(['tries', 'to', 'rush', 'through', 'the', 'intermediary', 'passages', ',', 'apparently', 'hoping', 'that', 'the', 'audience', 'will', 'not', 'notice', 'the', 'glaring', 'triteness', 'of', 'the', 'plot', 'device'], 1)\n",
      "(['flawed', 'but'], 1)\n",
      "(['a', 'thunderous', 'ride'], 3)\n",
      "(['blaring'], 2)\n",
      "(['is', '-rrb-', 'one', 'of', 'the', 'few', 'reasons', 'to', 'watch', 'the', 'film', ',', 'which', 'director', 'gerardo', 'vera', 'has', 'drenched', 'in', 'swoony', 'music', 'and', 'fever-pitched', 'melodrama'], 3)\n",
      "(['its', 'stars'], 2)\n",
      "(['personal', 'low'], 1)\n",
      "(['half-an-hour', 'long'], 2)\n",
      "(['there', 'are', 'some', 'movies', 'that', 'hit', 'you', 'from', 'the', 'first', 'scene', 'and', 'you', 'know', 'it', \"'s\", 'going', 'to', 'be', 'a', 'trip'], 3)\n"
     ]
    }
   ],
   "source": [
    "  # possibly filter tokens\n",
    "  # lowercase - each phrase is a pair consisting of a token list and a label\n",
    "  docs = []\n",
    "  for phrase in phrasedocs:\n",
    "    lowerphrase = ([w.lower() for w in phrase[0]], phrase[1])\n",
    "    docs.append (lowerphrase)\n",
    "  # print a few\n",
    "  for phrase in docs[:10]:\n",
    "    print (phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10377\n"
     ]
    }
   ],
   "source": [
    "  # continue as usual to get all words and create word features\n",
    "  all_words_list = [word for (sent,cat) in docs for word in sent]\n",
    "  all_words = nltk.FreqDist(all_words_list)\n",
    "  print(len(all_words))\n",
    "\n",
    "  # get the 1500 most frequently appearing keywords in the corpus\n",
    "  word_items = all_words.most_common(1500)\n",
    "  word_features = [word for (word,count) in word_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Creates a feature set for unigram baseline ##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a feature definition function here <<<<<<<<<<<<<<------ Do this Ken!\n",
    "\n",
    "# use NLTK to compute evaluation measures from a reflist of gold labels\n",
    "#    and a testlist of predicted labels for all labels in a list\n",
    "# returns lists of precision and recall for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function define features (keywords) of a document for a BOW/unigram baseline\n",
    "# each feature is 'V_(keyword)' and is true or false depending\n",
    "# on whether that keyword is in the document\n",
    "def document_features(docs, word_features):\n",
    "    document_words = set(docs)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['V_{}'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features sets for a document, including keyword features and category feature\n",
    "featuresets = [(document_features(d, word_features), c) for (d, c) in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'V_the': True,\n",
       "  'V_,': False,\n",
       "  'V_a': False,\n",
       "  'V_and': False,\n",
       "  'V_of': True,\n",
       "  'V_to': False,\n",
       "  'V_.': False,\n",
       "  \"V_'s\": False,\n",
       "  'V_in': False,\n",
       "  'V_is': False,\n",
       "  'V_that': False,\n",
       "  'V_it': False,\n",
       "  'V_as': False,\n",
       "  'V_with': False,\n",
       "  'V_for': False,\n",
       "  'V_an': False,\n",
       "  'V_film': False,\n",
       "  'V_its': False,\n",
       "  'V_movie': False,\n",
       "  'V_this': False,\n",
       "  'V_but': False,\n",
       "  'V_on': False,\n",
       "  'V_be': False,\n",
       "  'V_you': False,\n",
       "  \"V_n't\": False,\n",
       "  'V_his': False,\n",
       "  'V_by': False,\n",
       "  'V_at': False,\n",
       "  'V_--': False,\n",
       "  'V_from': False,\n",
       "  'V_more': False,\n",
       "  'V_or': False,\n",
       "  'V_``': False,\n",
       "  'V_one': False,\n",
       "  'V_about': False,\n",
       "  'V_has': False,\n",
       "  'V_than': False,\n",
       "  'V_not': False,\n",
       "  'V_all': False,\n",
       "  'V_have': False,\n",
       "  \"V_'\": False,\n",
       "  'V_like': False,\n",
       "  'V_are': False,\n",
       "  'V_story': False,\n",
       "  'V_-rrb-': False,\n",
       "  'V_into': False,\n",
       "  'V_so': False,\n",
       "  'V_good': False,\n",
       "  'V_who': False,\n",
       "  'V_what': False,\n",
       "  'V_out': False,\n",
       "  'V_their': False,\n",
       "  'V_most': False,\n",
       "  'V_time': False,\n",
       "  'V_-lrb-': False,\n",
       "  'V_...': False,\n",
       "  'V_up': False,\n",
       "  'V_if': False,\n",
       "  'V_can': False,\n",
       "  'V_i': False,\n",
       "  'V_characters': False,\n",
       "  'V_`': False,\n",
       "  'V_too': False,\n",
       "  'V_does': False,\n",
       "  'V_funny': False,\n",
       "  'V_comedy': False,\n",
       "  'V_just': False,\n",
       "  'V_much': False,\n",
       "  'V_very': False,\n",
       "  'V_no': False,\n",
       "  'V_some': False,\n",
       "  'V_your': False,\n",
       "  'V_will': False,\n",
       "  'V_which': False,\n",
       "  'V_there': False,\n",
       "  'V_way': False,\n",
       "  'V_do': False,\n",
       "  'V_work': False,\n",
       "  'V_new': False,\n",
       "  'V_life': False,\n",
       "  'V_he': False,\n",
       "  'V_only': False,\n",
       "  'V_little': False,\n",
       "  'V_movies': False,\n",
       "  'V_make': False,\n",
       "  'V_even': False,\n",
       "  'V_was': False,\n",
       "  'V_been': False,\n",
       "  'V_enough': False,\n",
       "  'V_her': False,\n",
       "  'V_bad': False,\n",
       "  'V_they': False,\n",
       "  'V_many': False,\n",
       "  'V_never': False,\n",
       "  'V_character': False,\n",
       "  'V_love': False,\n",
       "  'V_when': False,\n",
       "  'V_director': False,\n",
       "  'V_them': False,\n",
       "  'V_really': False,\n",
       "  'V_any': False,\n",
       "  'V_would': False,\n",
       "  'V_we': False,\n",
       "  'V_audience': False,\n",
       "  'V_own': False,\n",
       "  'V_something': False,\n",
       "  'V_two': False,\n",
       "  'V_through': False,\n",
       "  'V_world': False,\n",
       "  'V_us': False,\n",
       "  'V_get': False,\n",
       "  'V_few': False,\n",
       "  'V_could': False,\n",
       "  'V_people': False,\n",
       "  'V_another': False,\n",
       "  'V_look': False,\n",
       "  'V_long': False,\n",
       "  'V_films': False,\n",
       "  'V_action': False,\n",
       "  'V_those': False,\n",
       "  'V_see': False,\n",
       "  'V_made': False,\n",
       "  'V_nothing': False,\n",
       "  'V_better': False,\n",
       "  'V_how': False,\n",
       "  'V_other': False,\n",
       "  'V_best': False,\n",
       "  'V_plot': False,\n",
       "  'V_well': False,\n",
       "  'V_makes': False,\n",
       "  'V_performances': False,\n",
       "  'V_man': False,\n",
       "  'V_may': False,\n",
       "  'V_still': False,\n",
       "  'V_old': False,\n",
       "  'V_these': False,\n",
       "  'V_between': False,\n",
       "  'V_thriller': False,\n",
       "  'V_such': False,\n",
       "  'V_screen': False,\n",
       "  \"V_'re\": False,\n",
       "  'V_should': False,\n",
       "  'V_performance': False,\n",
       "  'V_heart': False,\n",
       "  'V_first': False,\n",
       "  'V_humor': False,\n",
       "  'V_minutes': False,\n",
       "  'V_being': False,\n",
       "  'V_ever': False,\n",
       "  'V_were': False,\n",
       "  'V_almost': False,\n",
       "  'V_kind': False,\n",
       "  'V_drama': False,\n",
       "  'V_without': False,\n",
       "  'V_-': False,\n",
       "  'V_after': False,\n",
       "  'V_less': False,\n",
       "  'V_actors': False,\n",
       "  'V_quite': False,\n",
       "  'V_had': False,\n",
       "  'V_:': False,\n",
       "  'V_our': False,\n",
       "  'V_because': False,\n",
       "  'V_off': False,\n",
       "  'V_great': False,\n",
       "  'V_while': False,\n",
       "  'V_material': False,\n",
       "  'V_picture': False,\n",
       "  'V_original': False,\n",
       "  'V_cast': False,\n",
       "  'V_also': False,\n",
       "  'V_sense': False,\n",
       "  'V_fun': False,\n",
       "  'V_yet': False,\n",
       "  'V_over': False,\n",
       "  'V_moments': False,\n",
       "  'V_every': False,\n",
       "  'V_anything': False,\n",
       "  'V_interesting': False,\n",
       "  'V_american': False,\n",
       "  'V_young': False,\n",
       "  'V_seen': False,\n",
       "  \"V_'ll\": False,\n",
       "  'V_human': False,\n",
       "  'V_both': False,\n",
       "  'V_my': False,\n",
       "  'V_things': False,\n",
       "  'V_go': False,\n",
       "  'V_dialogue': False,\n",
       "  'V_emotional': False,\n",
       "  'V_feels': False,\n",
       "  'V_same': False,\n",
       "  'V_script': False,\n",
       "  'V_give': False,\n",
       "  'V_here': False,\n",
       "  'V_watching': False,\n",
       "  'V_cinema': False,\n",
       "  'V_rather': False,\n",
       "  'V_find': False,\n",
       "  'V_end': False,\n",
       "  'V_music': False,\n",
       "  'V_scenes': False,\n",
       "  'V_years': False,\n",
       "  'V_comic': False,\n",
       "  'V_full': False,\n",
       "  'V_feel': False,\n",
       "  'V_often': False,\n",
       "  'V_special': False,\n",
       "  'V_real': False,\n",
       "  'V_anyone': False,\n",
       "  'V_down': False,\n",
       "  'V_him': False,\n",
       "  'V_hollywood': False,\n",
       "  'V_right': False,\n",
       "  'V_big': False,\n",
       "  'V_take': False,\n",
       "  'V_become': False,\n",
       "  'V_back': False,\n",
       "  'V_watch': False,\n",
       "  'V_though': False,\n",
       "  'V_worth': False,\n",
       "  'V_itself': False,\n",
       "  'V_last': False,\n",
       "  'V_lot': False,\n",
       "  'V_romantic': False,\n",
       "  'V_acting': False,\n",
       "  'V_far': False,\n",
       "  'V_documentary': False,\n",
       "  'V_takes': False,\n",
       "  'V_dark': False,\n",
       "  'V_style': False,\n",
       "  'V_entertaining': False,\n",
       "  'V_hard': False,\n",
       "  'V_seems': False,\n",
       "  'V_theater': False,\n",
       "  'V_point': False,\n",
       "  'V_visual': False,\n",
       "  'V_know': False,\n",
       "  'V_works': False,\n",
       "  'V_genre': False,\n",
       "  'V_entertainment': False,\n",
       "  'V_?': False,\n",
       "  'V_war': False,\n",
       "  'V_family': False,\n",
       "  'V_art': False,\n",
       "  'V_might': False,\n",
       "  'V_keep': False,\n",
       "  'V_video': False,\n",
       "  'V_going': False,\n",
       "  'V_tale': False,\n",
       "  'V_ultimately': False,\n",
       "  'V_nearly': False,\n",
       "  'V_times': False,\n",
       "  'V_personal': False,\n",
       "  'V_compelling': False,\n",
       "  'V_direction': False,\n",
       "  'V_culture': False,\n",
       "  'V_fans': False,\n",
       "  'V_around': False,\n",
       "  'V_before': False,\n",
       "  'V_three': False,\n",
       "  'V_comes': False,\n",
       "  'V_bit': False,\n",
       "  'V_;': False,\n",
       "  'V_care': False,\n",
       "  'V_romance': False,\n",
       "  'V_once': False,\n",
       "  'V_where': False,\n",
       "  'V_moving': False,\n",
       "  'V_effort': False,\n",
       "  'V_making': False,\n",
       "  'V_premise': False,\n",
       "  'V_summer': False,\n",
       "  'V_need': False,\n",
       "  'V_again': False,\n",
       "  'V_subject': False,\n",
       "  'V_idea': False,\n",
       "  'V_kids': False,\n",
       "  'V_sweet': False,\n",
       "  'V_everything': False,\n",
       "  'V_ca': False,\n",
       "  'V_part': False,\n",
       "  'V_star': False,\n",
       "  'V_always': False,\n",
       "  'V_together': False,\n",
       "  'V_children': False,\n",
       "  'V_energy': False,\n",
       "  'V_me': False,\n",
       "  'V_laughs': False,\n",
       "  'V_show': False,\n",
       "  'V_himself': False,\n",
       "  'V_power': False,\n",
       "  'V_instead': False,\n",
       "  'V_screenplay': False,\n",
       "  'V_dull': False,\n",
       "  'V_come': False,\n",
       "  'V_gives': False,\n",
       "  'V_strong': False,\n",
       "  'V_title': False,\n",
       "  'V_seem': False,\n",
       "  'V_left': False,\n",
       "  'V_since': False,\n",
       "  'V_day': False,\n",
       "  'V_effects': False,\n",
       "  'V_face': False,\n",
       "  'V_want': False,\n",
       "  'V_tv': False,\n",
       "  'V_least': False,\n",
       "  'V_pretty': False,\n",
       "  'V_audiences': False,\n",
       "  'V_piece': False,\n",
       "  'V_set': False,\n",
       "  'V_thought': False,\n",
       "  'V_then': False,\n",
       "  'V_cinematic': False,\n",
       "  'V_else': False,\n",
       "  'V_fascinating': False,\n",
       "  'V_engaging': False,\n",
       "  'V_year': False,\n",
       "  'V_despite': False,\n",
       "  'V_women': False,\n",
       "  \"V_'ve\": False,\n",
       "  'V_narrative': False,\n",
       "  'V_short': False,\n",
       "  'V_why': False,\n",
       "  'V_gets': False,\n",
       "  'V_familiar': False,\n",
       "  'V_violence': False,\n",
       "  'V_sometimes': False,\n",
       "  'V_filmmaking': False,\n",
       "  'V_series': False,\n",
       "  'V_lack': False,\n",
       "  'V_head': False,\n",
       "  'V_predictable': False,\n",
       "  'V_home': False,\n",
       "  'V_either': False,\n",
       "  'V_away': False,\n",
       "  'V_wo': False,\n",
       "  'V_think': False,\n",
       "  'V_history': False,\n",
       "  'V_charming': False,\n",
       "  'V_high': False,\n",
       "  'V_dramatic': False,\n",
       "  'V_place': False,\n",
       "  'V_viewer': False,\n",
       "  'V_written': False,\n",
       "  'V_small': False,\n",
       "  'V_camera': False,\n",
       "  'V_goes': False,\n",
       "  'V_horror': False,\n",
       "  'V_modern': False,\n",
       "  'V_feature': False,\n",
       "  'V_past': False,\n",
       "  'V_interest': False,\n",
       "  'V_tone': False,\n",
       "  'V_version': False,\n",
       "  'V_straight': False,\n",
       "  'V_looking': False,\n",
       "  'V_actually': False,\n",
       "  'V_middle': False,\n",
       "  'V_lives': False,\n",
       "  'V_especially': False,\n",
       "  'V_say': False,\n",
       "  'V_study': False,\n",
       "  'V_contrived': False,\n",
       "  'V_debut': False,\n",
       "  'V_sort': False,\n",
       "  'V_fairly': False,\n",
       "  'V_death': False,\n",
       "  'V_hour': False,\n",
       "  'V_level': False,\n",
       "  'V_beyond': False,\n",
       "  'V_john': False,\n",
       "  'V_social': False,\n",
       "  'V_true': False,\n",
       "  'V_certainly': False,\n",
       "  'V_appeal': False,\n",
       "  'V_ideas': False,\n",
       "  'V_worst': False,\n",
       "  'V_events': False,\n",
       "  'V_mood': False,\n",
       "  'V_trying': False,\n",
       "  'V_easily': False,\n",
       "  'V_tragedy': False,\n",
       "  'V_deeply': False,\n",
       "  'V_eyes': False,\n",
       "  'V_attempt': False,\n",
       "  'V_smart': False,\n",
       "  'V_different': False,\n",
       "  'V_done': False,\n",
       "  'V_powerful': False,\n",
       "  'V_hours': False,\n",
       "  'V_amusing': False,\n",
       "  'V_mind': False,\n",
       "  'V_turns': False,\n",
       "  'V_classic': False,\n",
       "  'V_book': False,\n",
       "  'V_easy': False,\n",
       "  'V_rich': False,\n",
       "  'V_project': False,\n",
       "  'V_beautiful': False,\n",
       "  'V_matter': False,\n",
       "  'V_clever': False,\n",
       "  'V_wrong': False,\n",
       "  'V_perfect': False,\n",
       "  'V_thing': False,\n",
       "  'V_above': False,\n",
       "  'V_fresh': False,\n",
       "  'V_having': False,\n",
       "  'V_stories': False,\n",
       "  'V_each': False,\n",
       "  'V_filmmakers': False,\n",
       "  'V_change': False,\n",
       "  'V_turn': False,\n",
       "  'V_passion': False,\n",
       "  'V_intriguing': False,\n",
       "  'V_charm': False,\n",
       "  'V_found': False,\n",
       "  'V_truly': False,\n",
       "  'V_plays': False,\n",
       "  'V_scene': False,\n",
       "  'V_particularly': False,\n",
       "  'V_act': False,\n",
       "  'V_suspense': False,\n",
       "  'V_manages': False,\n",
       "  'V_ugly': False,\n",
       "  'V_certain': False,\n",
       "  'V_surprisingly': False,\n",
       "  'V_gags': False,\n",
       "  'V_intelligence': False,\n",
       "  'V_girl': False,\n",
       "  \"V_'d\": False,\n",
       "  'V_put': False,\n",
       "  'V_half': False,\n",
       "  'V_whole': False,\n",
       "  'V_running': False,\n",
       "  'V_feeling': False,\n",
       "  'V_sharp': False,\n",
       "  'V_issues': False,\n",
       "  'V_michael': False,\n",
       "  'V_themselves': False,\n",
       "  'V_wife': False,\n",
       "  'V_mr.': False,\n",
       "  'V_fantasy': False,\n",
       "  'V_simply': False,\n",
       "  'V_adventure': False,\n",
       "  'V_sentimental': False,\n",
       "  'V_mystery': False,\n",
       "  'V_probably': False,\n",
       "  'V_intelligent': False,\n",
       "  'V_bland': False,\n",
       "  'V_occasionally': False,\n",
       "  'V_given': False,\n",
       "  'V_during': False,\n",
       "  'V_boy': False,\n",
       "  'V_line': False,\n",
       "  'V_artist': False,\n",
       "  'V_depth': False,\n",
       "  'V_storytelling': False,\n",
       "  'V_remarkable': False,\n",
       "  'V_men': False,\n",
       "  'V_comedies': False,\n",
       "  'V_light': False,\n",
       "  'V_spy': False,\n",
       "  'V_finally': False,\n",
       "  'V_fine': False,\n",
       "  'V_likely': False,\n",
       "  'V_dead': False,\n",
       "  'V_thoroughly': False,\n",
       "  'V_cool': False,\n",
       "  'V_impossible': False,\n",
       "  'V_cold': False,\n",
       "  'V_she': False,\n",
       "  'V_spiritual': False,\n",
       "  'V_did': False,\n",
       "  'V_de': False,\n",
       "  'V_next': False,\n",
       "  'V_guy': False,\n",
       "  'V_episode': False,\n",
       "  'V_date': False,\n",
       "  'V_couple': False,\n",
       "  'V_days': False,\n",
       "  'V_protagonist': False,\n",
       "  'V_cliches': False,\n",
       "  'V_ii': False,\n",
       "  'V_woman': False,\n",
       "  'V_sad': False,\n",
       "  'V_complex': False,\n",
       "  'V_guys': False,\n",
       "  'V_directed': False,\n",
       "  'V_unsettling': False,\n",
       "  'V_enjoy': False,\n",
       "  'V_cut': False,\n",
       "  'V_sequel': False,\n",
       "  'V_proves': False,\n",
       "  'V_usual': False,\n",
       "  'V_political': False,\n",
       "  'V_themes': False,\n",
       "  'V_ways': False,\n",
       "  'V_york': False,\n",
       "  'V_job': False,\n",
       "  'V_actor': False,\n",
       "  'V_french': False,\n",
       "  'V_hold': False,\n",
       "  'V_flick': False,\n",
       "  \"V_'m\": False,\n",
       "  'V_believe': False,\n",
       "  'V_core': False,\n",
       "  'V_hero': False,\n",
       "  'V_tell': False,\n",
       "  'V_already': False,\n",
       "  'V_exercise': False,\n",
       "  'V_portrait': False,\n",
       "  'V_lost': False,\n",
       "  'V_role': False,\n",
       "  'V_form': False,\n",
       "  'V_game': False,\n",
       "  'V_solid': False,\n",
       "  'V_stuff': False,\n",
       "  'V_now': False,\n",
       "  'V_silly': False,\n",
       "  'V_knows': False,\n",
       "  'V_recent': False,\n",
       "  'V_tries': False,\n",
       "  'V_flawed': False,\n",
       "  'V_low': False,\n",
       "  'V_hit': False,\n",
       "  'V_country': False,\n",
       "  'V_final': False,\n",
       "  'V_becomes': False,\n",
       "  'V_live': False,\n",
       "  'V_!': False,\n",
       "  'V_reason': False,\n",
       "  'V_view': False,\n",
       "  'V_relationships': False,\n",
       "  'V_black': False,\n",
       "  'V_hilarious': False,\n",
       "  'V_essentially': False,\n",
       "  'V_mostly': False,\n",
       "  'V_creepy': False,\n",
       "  'V_career': False,\n",
       "  'V_satire': False,\n",
       "  'V_experience': False,\n",
       "  'V_flaws': False,\n",
       "  'V_talent': False,\n",
       "  'V_leave': False,\n",
       "  'V_creative': False,\n",
       "  'V_beautifully': False,\n",
       "  'V_fact': False,\n",
       "  'V_emotions': False,\n",
       "  'V_unexpected': False,\n",
       "  'V_under': False,\n",
       "  'V_strangely': False,\n",
       "  'V_huge': False,\n",
       "  'V_obvious': False,\n",
       "  'V_pop': False,\n",
       "  'V_everyone': False,\n",
       "  'V_visually': False,\n",
       "  'V_side': False,\n",
       "  'V_sure': False,\n",
       "  'V_enjoyable': False,\n",
       "  'V_excellent': False,\n",
       "  'V_quirky': False,\n",
       "  'V_gone': False,\n",
       "  'V_wonderful': False,\n",
       "  'V_drag': False,\n",
       "  'V_sequences': False,\n",
       "  'V_age': False,\n",
       "  'V_tedious': False,\n",
       "  'V_sex': False,\n",
       "  'V_possible': False,\n",
       "  'V_told': False,\n",
       "  'V_awful': False,\n",
       "  'V_gorgeous': False,\n",
       "  'V_jokes': False,\n",
       "  'V_today': False,\n",
       "  'V_ride': False,\n",
       "  'V_difficult': False,\n",
       "  'V_looks': False,\n",
       "  'V_greatest': False,\n",
       "  'V_pace': False,\n",
       "  'V_viewers': False,\n",
       "  'V_open': False,\n",
       "  'V_working': False,\n",
       "  'V_moment': False,\n",
       "  'V_perfectly': False,\n",
       "  'V_moral': False,\n",
       "  'V_help': False,\n",
       "  'V_bring': False,\n",
       "  'V_psychological': False,\n",
       "  'V_satisfying': False,\n",
       "  'V_situations': False,\n",
       "  'V_second': False,\n",
       "  'V_crime': False,\n",
       "  'V_rock': False,\n",
       "  'V_beauty': False,\n",
       "  'V_serious': False,\n",
       "  'V_frank': False,\n",
       "  'V_robert': False,\n",
       "  'V_message': False,\n",
       "  'V_shot': False,\n",
       "  'V_taking': False,\n",
       "  'V_target': False,\n",
       "  'V_saw': False,\n",
       "  'V_problem': False,\n",
       "  'V_terrific': False,\n",
       "  'V_inside': False,\n",
       "  'V_exactly': False,\n",
       "  'V_thoughtful': False,\n",
       "  'V_sloppy': False,\n",
       "  'V_wild': False,\n",
       "  'V_twists': False,\n",
       "  'V_offer': False,\n",
       "  'V_memorable': False,\n",
       "  'V_remake': False,\n",
       "  'V_conclusion': False,\n",
       "  'V_believable': False,\n",
       "  'V_dumb': False,\n",
       "  'V_fails': False,\n",
       "  'V_disney': False,\n",
       "  'V_justice': False,\n",
       "  'V_several': False,\n",
       "  'V_melodrama': False,\n",
       "  'V_slow': False,\n",
       "  'V_completely': False,\n",
       "  'V_members': False,\n",
       "  'V_writing': False,\n",
       "  'V_word': False,\n",
       "  'V_historical': False,\n",
       "  'V_bizarre': False,\n",
       "  'V_behind': False,\n",
       "  'V_90': False,\n",
       "  'V_pleasure': False,\n",
       "  'V_read': False,\n",
       "  'V_period': False,\n",
       "  'V_plenty': False,\n",
       "  'V_neither': False,\n",
       "  'V_sides': False,\n",
       "  'V_fully': False,\n",
       "  'V_odd': False,\n",
       "  'V_writer': False,\n",
       "  'V_mediocre': False,\n",
       "  'V_allows': False,\n",
       "  'V_kid': False,\n",
       "  'V_somewhat': False,\n",
       "  'V_taste': False,\n",
       "  'V_filmmaker': False,\n",
       "  'V_vision': False,\n",
       "  'V_case': False,\n",
       "  'V_purpose': False,\n",
       "  'V_considerable': False,\n",
       "  'V_flat': False,\n",
       "  'V_touch': False,\n",
       "  'V_warm': False,\n",
       "  'V_cause': False,\n",
       "  'V_silver': False,\n",
       "  'V_add': False,\n",
       "  'V_bullock': False,\n",
       "  'V_potential': False,\n",
       "  'V_welcome': False,\n",
       "  'V_pictures': False,\n",
       "  'V_run': False,\n",
       "  'V_clarity': False,\n",
       "  'V_against': False,\n",
       "  'V_questions': False,\n",
       "  'V_places': False,\n",
       "  'V_faith': False,\n",
       "  'V_strange': False,\n",
       "  'V_whatever': False,\n",
       "  'V_grant': False,\n",
       "  'V_spirit': False,\n",
       "  'V_wanted': False,\n",
       "  'V_writer-director': False,\n",
       "  'V_gross-out': False,\n",
       "  'V_fit': False,\n",
       "  'V_memory': False,\n",
       "  'V_score': False,\n",
       "  'V_sincere': False,\n",
       "  'V_production': False,\n",
       "  'V_mess': False,\n",
       "  'V_truth': False,\n",
       "  'V_among': False,\n",
       "  'V_terrible': False,\n",
       "  'V_thinking': False,\n",
       "  'V_rare': False,\n",
       "  'V_ends': False,\n",
       "  'V_entirely': False,\n",
       "  'V_jackson': False,\n",
       "  'V_haunting': False,\n",
       "  'V_important': False,\n",
       "  'V_remains': False,\n",
       "  'V_nor': False,\n",
       "  'V_captures': False,\n",
       "  'V_pacing': False,\n",
       "  'V_effective': False,\n",
       "  'V_house': False,\n",
       "  'V_winning': False,\n",
       "  'V_credit': False,\n",
       "  'V_reality': False,\n",
       "  'V_throughout': False,\n",
       "  'V_gay': False,\n",
       "  'V_games': False,\n",
       "  'V_shows': False,\n",
       "  'V_surprise': False,\n",
       "  'V_honest': False,\n",
       "  'V_adult': False,\n",
       "  'V_ending': False,\n",
       "  'V_product': False,\n",
       "  'V_simplistic': False,\n",
       "  'V_deep': False,\n",
       "  'V_offers': False,\n",
       "  'V_ago': False,\n",
       "  'V_hits': False,\n",
       "  'V_money': False,\n",
       "  'V_whom': False,\n",
       "  'V_must': False,\n",
       "  'V_killer': False,\n",
       "  'V_desire': False,\n",
       "  'V_british': False,\n",
       "  'V_mainstream': False,\n",
       "  'V_answers': False,\n",
       "  'V_earnest': False,\n",
       "  'V_alone': False,\n",
       "  'V_elements': False,\n",
       "  'V_dog': False,\n",
       "  'V_reveals': False,\n",
       "  'V_parents': False,\n",
       "  'V_inspired': False,\n",
       "  'V_america': False,\n",
       "  'V_television': False,\n",
       "  'V_excuse': False,\n",
       "  'V_skin': False,\n",
       "  'V_class': False,\n",
       "  'V_brain': False,\n",
       "  'V_green': False,\n",
       "  'V_suffers': False,\n",
       "  'V_stock': False,\n",
       "  'V_painfully': False,\n",
       "  'V_entire': False,\n",
       "  'V_battle': False,\n",
       "  'V_watchable': False,\n",
       "  'V_coming': False,\n",
       "  'V_laugh': False,\n",
       "  'V_served': False,\n",
       "  'V_broken': False,\n",
       "  'V_mean': False,\n",
       "  'V_clear': False,\n",
       "  'V_source': False,\n",
       "  'V_major': False,\n",
       "  'V_david': False,\n",
       "  'V_dvd': False,\n",
       "  'V_intended': False,\n",
       "  'V_execution': False,\n",
       "  'V_contemporary': False,\n",
       "  'V_problems': False,\n",
       "  'V_teenagers': False,\n",
       "  'V_supposed': False,\n",
       "  'V_images': False,\n",
       "  'V_twisted': False,\n",
       "  'V_taken': False,\n",
       "  'V_subtle': False,\n",
       "  'V_meditation': False,\n",
       "  'V_ambitious': False,\n",
       "  'V_whose': False,\n",
       "  'V_situation': False,\n",
       "  'V_\\\\': False,\n",
       "  'V_*': False,\n",
       "  'V_quiet': False,\n",
       "  'V_cultural': False,\n",
       "  'V_hope': False,\n",
       "  'V_x': False,\n",
       "  'V_worse': False,\n",
       "  'V_pointless': False,\n",
       "  'V_seeing': False,\n",
       "  'V_boring': False,\n",
       "  'V_otherwise': False,\n",
       "  'V_sandler': False,\n",
       "  'V_intrigue': False,\n",
       "  'V_relationship': False,\n",
       "  'V_trouble': False,\n",
       "  'V_intentions': False,\n",
       "  'V_trite': False,\n",
       "  'V_graphic': False,\n",
       "  'V_play': False,\n",
       "  'V_skill': False,\n",
       "  'V_lacks': False,\n",
       "  'V_bits': False,\n",
       "  'V_stupid': False,\n",
       "  'V_shallow': False,\n",
       "  'V_master': False,\n",
       "  'V_wit': False,\n",
       "  'V_formula': False,\n",
       "  'V_turned': False,\n",
       "  'V_shoot': False,\n",
       "  'V_successful': False,\n",
       "  \"V_''\": False,\n",
       "  'V_got': False,\n",
       "  'V_hell': False,\n",
       "  'V_plotting': False,\n",
       "  'V_promise': False,\n",
       "  'V_none': False,\n",
       "  'V_imagination': False,\n",
       "  'V_sophisticated': False,\n",
       "  'V_across': False,\n",
       "  'V_americans': False,\n",
       "  'V_sit': False,\n",
       "  'V_delivery': False,\n",
       "  'V_pretentious': False,\n",
       "  'V_lesson': False,\n",
       "  'V_wants': False,\n",
       "  'V_cute': False,\n",
       "  'V_expect': False,\n",
       "  'V_consolation': False,\n",
       "  'V_melodramatic': False,\n",
       "  'V_slapstick': False,\n",
       "  'V_editing': False,\n",
       "  'V_along': False,\n",
       "  'V_stylish': False,\n",
       "  'V_loves': False,\n",
       "  'V_future': False,\n",
       "  'V_pieces': False,\n",
       "  'V_tough': False,\n",
       "  'V_success': False,\n",
       "  'V_based': False,\n",
       "  'V_doubt': False,\n",
       "  'V_convincing': False,\n",
       "  'V_red': False,\n",
       "  'V_experiences': False,\n",
       "  'V_loss': False,\n",
       "  'V_opera': False,\n",
       "  'V_sounds': False,\n",
       "  'V_peter': False,\n",
       "  'V_popcorn': False,\n",
       "  'V_rest': False,\n",
       "  'V_faster': False,\n",
       "  'V_superficial': False,\n",
       "  'V_heavy': False,\n",
       "  'V_call': False,\n",
       "  'V_decent': False,\n",
       "  'V_unusual': False,\n",
       "  'V_pay': False,\n",
       "  'V_attention': False,\n",
       "  'V_created': False,\n",
       "  'V_brilliant': False,\n",
       "  'V_warmth': False,\n",
       "  'V_lovely': False,\n",
       "  'V_credits': False,\n",
       "  'V_let': False,\n",
       "  'V_coming-of-age': False,\n",
       "  'V_imagine': False,\n",
       "  'V_body': False,\n",
       "  'V_office': False,\n",
       "  'V_street': False,\n",
       "  'V_gangs': False,\n",
       "  'V_stale': False,\n",
       "  'V_oscar': False,\n",
       "  'V_female': False,\n",
       "  'V_nice': False,\n",
       "  'V_examination': False,\n",
       "  'V_south': False,\n",
       "  'V_ambition': False,\n",
       "  'V_approach': False,\n",
       "  'V_low-key': False,\n",
       "  'V_quick': False,\n",
       "  'V_sexual': False,\n",
       "  'V_thanks': False,\n",
       "  'V_attempts': False,\n",
       "  'V_sitting': False,\n",
       "  'V_chan': False,\n",
       "  'V_waste': False,\n",
       "  'V_novel': False,\n",
       "  'V_balance': False,\n",
       "  'V_adults': False,\n",
       "  'V_uneven': False,\n",
       "  'V_unique': False,\n",
       "  'V_2002': False,\n",
       "  'V_industry': False,\n",
       "  'V_delightful': False,\n",
       "  'V_used': False,\n",
       "  'V_able': False,\n",
       "  'V_pull': False,\n",
       "  'V_quality': False,\n",
       "  'V_cheap': False,\n",
       "  'V_pity': False,\n",
       "  'V_plain': False,\n",
       "  'V_scary': False,\n",
       "  'V_tension': False,\n",
       "  'V_twist': False,\n",
       "  'V_&': False,\n",
       "  'V_recommend': False,\n",
       "  'V_hate': False,\n",
       "  'V_edge': False,\n",
       "  'V_substantial': False,\n",
       "  'V_limited': False,\n",
       "  'V_process': False,\n",
       "  'V_slightly': False,\n",
       "  'V_genuine': False,\n",
       "  'V_spielberg': False,\n",
       "  'V_number': False,\n",
       "  'V_tired': False,\n",
       "  'V_eye': False,\n",
       "  'V_painful': False,\n",
       "  'V_air': False,\n",
       "  'V_animation': False,\n",
       "  'V_ones': False,\n",
       "  'V_appear': False,\n",
       "  'V_sets': False,\n",
       "  'V_fiction': False,\n",
       "  'V_proceedings': False,\n",
       "  'V_document': False,\n",
       "  'V_soon': False,\n",
       "  'V_overall': False,\n",
       "  'V_teen': False,\n",
       "  'V_nature': False,\n",
       "  'V_puts': False,\n",
       "  'V_behavior': False,\n",
       "  'V_absorbing': False,\n",
       "  'V_raw': False,\n",
       "  'V_disaster': False,\n",
       "  'V_barely': False,\n",
       "  'V_main': False,\n",
       "  'V_adam': False,\n",
       "  'V_previous': False,\n",
       "  'V_substance': False,\n",
       "  'V_simple': False,\n",
       "  'V_party': False,\n",
       "  'V_stand': False,\n",
       "  'V_break': False,\n",
       "  'V_front': False,\n",
       "  'V_whether': False,\n",
       "  'V_fix': False,\n",
       "  'V_keeps': False,\n",
       "  'V_gentle': False,\n",
       "  'V_false': False,\n",
       "  'V_knowledge': False,\n",
       "  'V_hardly': False,\n",
       "  'V_funnier': False,\n",
       "  'V_spin': False,\n",
       "  'V_polanski': False,\n",
       "  'V_inspiring': False,\n",
       "  'V_rarely': False,\n",
       "  'V_devastating': False,\n",
       "  'V_heaven': False,\n",
       "  'V_forget': False,\n",
       "  'V_stand-up': False,\n",
       "  'V_damned': True,\n",
       "  'V_free': False,\n",
       "  'V_involving': False,\n",
       "  'V_crowd': False,\n",
       "  'V_ode': False,\n",
       "  'V_impressive': False,\n",
       "  'V_highly': False,\n",
       "  'V_dry': False,\n",
       "  'V_bunch': False,\n",
       "  'V_city': False,\n",
       "  'V_equally': False,\n",
       "  'V_mesmerizing': False,\n",
       "  'V_treatment': False,\n",
       "  'V_weird': False,\n",
       "  'V_yarn': False,\n",
       "  'V_try': False,\n",
       "  'V_hand': False,\n",
       "  'V_road': False,\n",
       "  'V_manipulative': False,\n",
       "  'V_affection': False,\n",
       "  'V_holocaust': False,\n",
       "  'V_misery': False,\n",
       "  'V_cloying': False,\n",
       "  'V_quietly': False,\n",
       "  'V_motion': False,\n",
       "  'V_dawson': False,\n",
       "  'V_politics': False,\n",
       "  'V_appealing': False,\n",
       "  'V_directing': False,\n",
       "  'V_white': False,\n",
       "  'V_wise': False,\n",
       "  'V_talented': False,\n",
       "  'V_degree': False,\n",
       "  'V_boys': False,\n",
       "  'V_close': False,\n",
       "  'V_imitation': False,\n",
       "  'V_witty': False,\n",
       "  'V_happened': False,\n",
       "  'V_voice': False,\n",
       "  'V_personality': False,\n",
       "  'V_empty': False,\n",
       "  'V_season': False,\n",
       "  'V_loud': False,\n",
       "  'V_produced': False,\n",
       "  'V_lady': False,\n",
       "  'V_understand': False,\n",
       "  'V_society': False,\n",
       "  'V_urban': False,\n",
       "  'V_barbershop': False,\n",
       "  'V_subtlety': False,\n",
       "  'V_fall': False,\n",
       "  'V_others': False,\n",
       "  'V_meaning': False,\n",
       "  'V_touching': False,\n",
       "  'V_neat': False,\n",
       "  ...},\n",
       " 3)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[5000:], featuresets[:5000]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                  V_ugly = True                0 : 2      =     48.2 : 1.0\n",
      "                 V_hours = True                0 : 2      =     40.8 : 1.0\n",
      "                V_images = True                4 : 2      =     34.3 : 1.0\n",
      "                 V_awful = True                0 : 2      =     33.4 : 1.0\n",
      "                  V_lack = True                0 : 2      =     33.4 : 1.0\n",
      "               V_tedious = True                0 : 2      =     33.4 : 1.0\n",
      "                  V_year = True                4 : 2      =     28.1 : 1.0\n",
      "                  V_adam = True                0 : 2      =     26.0 : 1.0\n",
      "                  V_care = True                0 : 2      =     26.0 : 1.0\n",
      "                  V_core = True                0 : 2      =     26.0 : 1.0\n",
      "                  V_mess = True                0 : 2      =     26.0 : 1.0\n",
      "                   V_put = True                0 : 2      =     26.0 : 1.0\n",
      "               V_sandler = True                0 : 2      =     26.0 : 1.0\n",
      "                  V_seem = True                0 : 2      =     26.0 : 1.0\n",
      "               V_sitting = True                0 : 2      =     26.0 : 1.0\n",
      "          V_performances = True                4 : 2      =     24.3 : 1.0\n",
      "                 V_still = True                4 : 2      =     24.3 : 1.0\n",
      "                V_beauty = True                4 : 2      =     21.8 : 1.0\n",
      "               V_classic = True                4 : 2      =     21.8 : 1.0\n",
      "              V_deserves = True                4 : 2      =     21.8 : 1.0\n",
      "            V_engrossing = True                4 : 2      =     21.8 : 1.0\n",
      "               V_perfect = True                4 : 2      =     21.8 : 1.0\n",
      "                 V_piece = True                4 : 2      =     21.8 : 1.0\n",
      "            V_production = True                4 : 2      =     21.8 : 1.0\n",
      "                V_subtle = True                4 : 2      =     21.8 : 1.0\n",
      "              V_terrific = True                4 : 2      =     21.8 : 1.0\n",
      "             V_audiences = True                0 : 2      =     20.0 : 1.0\n",
      "                 V_silly = True                0 : 2      =     20.0 : 1.0\n",
      "                V_simply = True                0 : 2      =     20.0 : 1.0\n",
      "               V_theater = True                0 : 2      =     20.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################### cross-validation for UNIGRAMS ##\n",
    "# this function takes the number of folds, the feature sets\n",
    "# it iterates over the folds, using different sections for training and testing in turn\n",
    "#   it prints the accuracy for each fold and the average accuracy at the end\n",
    "def cross_validation_accuracy(num_folds, featuresets):\n",
    "    subset_size = int(len(featuresets)/num_folds)\n",
    "    print('Each fold size:', subset_size)\n",
    "    accuracy_list = []\n",
    "    # iterate over the folds\n",
    "    for i in range(num_folds):\n",
    "        test_this_round = featuresets[(i*subset_size):][:subset_size]\n",
    "        train_this_round = featuresets[:(i*subset_size)] + featuresets[((i+1)*subset_size):]\n",
    "        # train using train_this_round\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_this_round)\n",
    "        # evaluate against test_this_round and save accuracy\n",
    "        accuracy_this_round = nltk.classify.accuracy(classifier, test_this_round)\n",
    "        print (i, accuracy_this_round)\n",
    "        accuracy_list.append(accuracy_this_round)\n",
    "    # find mean accuracy over all rounds\n",
    "    print ('mean accuracy', sum(accuracy_list) / num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each fold size: 1000\n",
      "0 0.549\n",
      "1 0.542\n",
      "2 0.537\n",
      "3 0.513\n",
      "4 0.542\n",
      "5 0.536\n",
      "6 0.546\n",
      "7 0.544\n",
      "8 0.544\n",
      "9 0.522\n",
      "mean accuracy 0.5375\n"
     ]
    }
   ],
   "source": [
    "# perform the cross-validation on the featuresets with word features and generate accuracy\n",
    "num_folds = 10\n",
    "cross_validation_accuracy(num_folds, featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## other evaluation measures:  confusion matrix, precision, recall, F1 ##\n",
    "\n",
    "goldlist = []\n",
    "predictedlist = []\n",
    "for (features, label) in test_set:\n",
    "    \tgoldlist.append(label)\n",
    "    \tpredictedlist.append(classifier.classify(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(goldlist[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |    2    3    1    4    0 |\n",
      "--+--------------------------+\n",
      "2 |<2068> 173  221   30   54 |\n",
      "3 |  554 <269> 119   53   64 |\n",
      "1 |  480   69 <223>  16   80 |\n",
      "4 |   99  100   20  <50>  24 |\n",
      "0 |   86   14   90    4  <40>|\n",
      "--+--------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = nltk.ConfusionMatrix(goldlist, predictedlist)\n",
    "print(cm.pretty_format(sort_by_count=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |      2      3      1      4      0 |\n",
      "--+------------------------------------+\n",
      "2 | <41.4%>  3.5%   4.4%   0.6%   1.1% |\n",
      "3 |  11.1%  <5.4%>  2.4%   1.1%   1.3% |\n",
      "1 |   9.6%   1.4%  <4.5%>  0.3%   1.6% |\n",
      "4 |   2.0%   2.0%   0.4%  <1.0%>  0.5% |\n",
      "0 |   1.7%   0.3%   1.8%   0.1%  <0.8%>|\n",
      "--+------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# or show the results as percentages\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute precision, recall and F1 for each label\n",
    "#  and for any number of labels\n",
    "# Input: list of gold labels, list of predicted labels (in same order)\n",
    "# Output:  prints precision, recall and F1 for each label\n",
    "def eval_measures(gold, predicted):\n",
    "    # get a list of labels\n",
    "    labels = list(set(gold))\n",
    "    # these lists have values for each label \n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    F1_list = []\n",
    "    for lab in labels:\n",
    "        # for each label, compare gold and predicted lists and compute values\n",
    "        TP = FP = FN = TN = 0\n",
    "        for i, val in enumerate(gold):\n",
    "            if val == lab and predicted[i] == lab:  TP += 1\n",
    "            if val == lab and predicted[i] != lab:  FN += 1\n",
    "            if val != lab and predicted[i] == lab:  FP += 1\n",
    "            if val != lab and predicted[i] != lab:  TN += 1\n",
    "        # use these to compute recall, precision, F1\n",
    "        recall = TP / (TP + FP)\n",
    "        precision = TP / (TP + FN)\n",
    "        recall_list.append(recall)\n",
    "        precision_list.append(precision)\n",
    "        F1_list.append( 2 * (recall * precision) / (recall + precision))\n",
    "    # the evaluation measures in a table with one row per label\n",
    "    print('\\tPrecision\\tRecall\\t\\tF1')\n",
    "    # print measures for each label\n",
    "    for i, lab in enumerate(labels):\n",
    "        print(lab, '\\t', \"{:10.3f}\".format(precision_list[i]), \\\n",
    "          \"{:10.3f}\".format(recall_list[i]), \"{:10.3f}\".format(F1_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPrecision\tRecall\t\tF1\n",
      "0 \t      0.171      0.153      0.161\n",
      "1 \t      0.257      0.331      0.289\n",
      "2 \t      0.812      0.629      0.709\n",
      "3 \t      0.254      0.430      0.319\n",
      "4 \t      0.171      0.327      0.224\n"
     ]
    }
   ],
   "source": [
    "# Basically this all replicates the train/test function as many times as you want (folds) with the cross-validation\n",
    "# function to test precision of the model\n",
    "# call the function with our data\n",
    "eval_measures(goldlist, predictedlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################### Subjectivity Feature #################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentiment_read_subjectivity\n",
    "(positivelist, neutrallist, negativelist) = sentiment_read_subjectivity.read_subjectivity_three_types('SentimentLexicons/subjclueslen1-HLTEMNLP05.tff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function returns a dictionary where you can look up words and get back \n",
    "#     the four items of subjectivity information described above\n",
    "def readSubjectivity(path):\n",
    "\tflexicon = open(path, 'r')\n",
    "\t# initialize an empty dictionary\n",
    "\tsldict = { }\n",
    "\tfor line in flexicon:\n",
    "\t\tfields = line.split()   # default is to split on whitespace\n",
    "\t\t# split each field on the '=' and keep the second part as the value\n",
    "\t\tstrength = fields[0].split(\"=\")[1]\n",
    "\t\tword = fields[2].split(\"=\")[1]\n",
    "\t\tposTag = fields[3].split(\"=\")[1]\n",
    "\t\tstemmed = fields[4].split(\"=\")[1]\n",
    "\t\tpolarity = fields[5].split(\"=\")[1]\n",
    "\t\tif (stemmed == 'y'):\n",
    "\t\t\tisStemmed = True\n",
    "\t\telse:\n",
    "\t\t\tisStemmed = False\n",
    "\t\t# put a dictionary entry with the word as the keyword\n",
    "\t\t#     and a list of the other values\n",
    "\t\tsldict[word] = [strength, posTag, isStemmed, polarity]\n",
    "\treturn sldict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/hub20/subjclueslen1-HLTEMNLP05.tff\"\n",
    "SL = readSubjectivity(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features that include word counts of subjectivity words\n",
    "# negative feature will have number of weakly negative words +\n",
    "#    2 * number of strongly negative words\n",
    "# positive feature has similar definition\n",
    "#    not counting neutral words\n",
    "def SL_features(docs, word_features, SL):\n",
    "    document_words = set(docs)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['V_{}'.format(word)] = (word in document_words)\n",
    "    # count variables for the 4 classes of subjectivity\n",
    "    weakPos = 0\n",
    "    strongPos = 0\n",
    "    weakNeg = 0\n",
    "    strongNeg = 0\n",
    "    for word in document_words:\n",
    "        if word in SL:\n",
    "            strength, posTag, isStemmed, polarity = SL[word]\n",
    "            if strength == 'weaksubj' and polarity == 'positive':\n",
    "                weakPos += 1\n",
    "            if strength == 'strongsubj' and polarity == 'positive':\n",
    "                strongPos += 1\n",
    "            if strength == 'weaksubj' and polarity == 'negative':\n",
    "                weakNeg += 1\n",
    "            if strength == 'strongsubj' and polarity == 'negative':\n",
    "                strongNeg += 1\n",
    "            features['positivecount'] = weakPos + (2 * strongPos)\n",
    "            features['negativecount'] = weakNeg + (2 * strongNeg)      \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "SL_featuresets = [(SL_features(d, word_features, SL), c) for (d, c) in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = SL_featuresets[5000:], SL_featuresets[:5000]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5332"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                  V_ugly = True                0 : 2      =     48.2 : 1.0\n",
      "                 V_hours = True                0 : 2      =     40.8 : 1.0\n",
      "                V_images = True                4 : 2      =     34.3 : 1.0\n",
      "                 V_awful = True                0 : 2      =     33.4 : 1.0\n",
      "                  V_lack = True                0 : 2      =     33.4 : 1.0\n",
      "               V_tedious = True                0 : 2      =     33.4 : 1.0\n",
      "           positivecount = 6                   4 : 2      =     29.6 : 1.0\n",
      "                  V_year = True                4 : 2      =     28.1 : 1.0\n",
      "                  V_adam = True                0 : 2      =     26.0 : 1.0\n",
      "                  V_care = True                0 : 2      =     26.0 : 1.0\n",
      "                  V_core = True                0 : 2      =     26.0 : 1.0\n",
      "                  V_mess = True                0 : 2      =     26.0 : 1.0\n",
      "                   V_put = True                0 : 2      =     26.0 : 1.0\n",
      "               V_sandler = True                0 : 2      =     26.0 : 1.0\n",
      "                  V_seem = True                0 : 2      =     26.0 : 1.0\n",
      "               V_sitting = True                0 : 2      =     26.0 : 1.0\n",
      "          V_performances = True                4 : 2      =     24.3 : 1.0\n",
      "                 V_still = True                4 : 2      =     24.3 : 1.0\n",
      "                V_beauty = True                4 : 2      =     21.8 : 1.0\n",
      "               V_classic = True                4 : 2      =     21.8 : 1.0\n",
      "              V_deserves = True                4 : 2      =     21.8 : 1.0\n",
      "            V_engrossing = True                4 : 2      =     21.8 : 1.0\n",
      "               V_perfect = True                4 : 2      =     21.8 : 1.0\n",
      "                 V_piece = True                4 : 2      =     21.8 : 1.0\n",
      "            V_production = True                4 : 2      =     21.8 : 1.0\n",
      "                V_subtle = True                4 : 2      =     21.8 : 1.0\n",
      "              V_terrific = True                4 : 2      =     21.8 : 1.0\n",
      "           positivecount = 7                   4 : 2      =     21.4 : 1.0\n",
      "             V_audiences = True                0 : 2      =     20.0 : 1.0\n",
      "                 V_silly = True                0 : 2      =     20.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################### cross-validation for subjectivity ##\n",
    "# this function takes the number of folds, the feature sets\n",
    "# it iterates over the folds, using different sections for training and testing in turn\n",
    "#   it prints the accuracy for each fold and the average accuracy at the end\n",
    "def cross_validation_accuracy(num_folds, SL_featuresets):\n",
    "    subset_size = int(len(SL_featuresets)/num_folds)\n",
    "    print('Each fold size:', subset_size)\n",
    "    accuracy_list = []\n",
    "    # iterate over the folds\n",
    "    for i in range(num_folds):\n",
    "        test_this_round = SL_featuresets[(i*subset_size):][:subset_size]\n",
    "        train_this_round = SL_featuresets[:(i*subset_size)] + SL_featuresets[((i+1)*subset_size):]\n",
    "        # train using train_this_round\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_this_round)\n",
    "        # evaluate against test_this_round and save accuracy\n",
    "        accuracy_this_round = nltk.classify.accuracy(classifier, test_this_round)\n",
    "        print (i, accuracy_this_round)\n",
    "        accuracy_list.append(accuracy_this_round)\n",
    "    # find mean accuracy over all rounds\n",
    "    print ('mean accuracy', sum(accuracy_list) / num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each fold size: 1000\n",
      "0 0.561\n",
      "1 0.544\n",
      "2 0.538\n",
      "3 0.532\n",
      "4 0.549\n",
      "5 0.55\n",
      "6 0.542\n",
      "7 0.564\n",
      "8 0.568\n",
      "9 0.545\n",
      "mean accuracy 0.5492999999999999\n"
     ]
    }
   ],
   "source": [
    "# perform the cross-validation on the featuresets with word features and generate accuracy\n",
    "num_folds = 10\n",
    "cross_validation_accuracy(num_folds, SL_featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "## other evaluation measures:  confusion matrix, precision, recall, F1 ##\n",
    "\n",
    "goldlist = []\n",
    "predictedlist = []\n",
    "for (features, label) in test_set:\n",
    "    \tgoldlist.append(label)\n",
    "    \tpredictedlist.append(classifier.classify(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |    2    3    1    4    0 |\n",
      "--+--------------------------+\n",
      "2 |<1893> 290  264   41   58 |\n",
      "3 |  402 <396> 115   80   66 |\n",
      "1 |  416   88 <262>  18   84 |\n",
      "4 |   52  133   16  <69>  23 |\n",
      "0 |   62   13  109    4  <46>|\n",
      "--+--------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = nltk.ConfusionMatrix(goldlist, predictedlist)\n",
    "print(cm.pretty_format(sort_by_count=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |      2      3      1      4      0 |\n",
      "--+------------------------------------+\n",
      "2 | <37.9%>  5.8%   5.3%   0.8%   1.2% |\n",
      "3 |   8.0%  <7.9%>  2.3%   1.6%   1.3% |\n",
      "1 |   8.3%   1.8%  <5.2%>  0.4%   1.7% |\n",
      "4 |   1.0%   2.7%   0.3%  <1.4%>  0.5% |\n",
      "0 |   1.2%   0.3%   2.2%   0.1%  <0.9%>|\n",
      "--+------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# or show the results as percentages\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPrecision\tRecall\t\tF1\n",
      "0 \t      0.197      0.166      0.180\n",
      "1 \t      0.302      0.342      0.321\n",
      "2 \t      0.744      0.670      0.705\n",
      "3 \t      0.374      0.430      0.400\n",
      "4 \t      0.235      0.325      0.273\n"
     ]
    }
   ],
   "source": [
    "# call the function with our data\n",
    "eval_measures(goldlist, predictedlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### Negation Feature ########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "negationwords = ['no', 'not', 'never', 'none', 'nowhere', 'nothing', 'noone', 'rather', 'hardly', 'scarcely', 'rarely', 'seldom', 'neither', 'nor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One strategy with negation words is to negate the word following the negation word\n",
    "#   other strategies negate all words up to the next punctuation\n",
    "# Strategy is to go through the document words in order adding the word features,\n",
    "#   but if the word follows a negation words, change the feature to negated word\n",
    "# Start the feature set with all 2000 word features and 2000 Not word features set to false\n",
    "def NOT_features(docs, word_features, negationwords):\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['V_{}'.format(word)] = False\n",
    "        features['V_NOT{}'.format(word)] = False\n",
    "    # go through document words in order\n",
    "    for i in range(0, len(docs)):\n",
    "        word = docs[i]\n",
    "        if ((i + 1) < len(docs)) and ((word in negationwords) or (word.endswith(\"n't\"))):\n",
    "            i += 1\n",
    "            features['V_NOT{}'.format(docs[i])] = (docs[i] in word_features)\n",
    "        else:\n",
    "            features['V_{}'.format(word)] = (word in word_features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOT_featuresets = [(NOT_features(d, word_features, negationwords), c) for (d, c) in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = NOT_featuresets[5000:], NOT_featuresets[:5000]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.513"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                  V_ugly = True                0 : 2      =     48.2 : 1.0\n",
      "                 V_hours = True                0 : 2      =     40.8 : 1.0\n",
      "                V_images = True                4 : 2      =     34.3 : 1.0\n",
      "             V_NOTreally = True                0 : 2      =     33.4 : 1.0\n",
      "                 V_awful = True                0 : 2      =     33.4 : 1.0\n",
      "                  V_lack = True                0 : 2      =     33.4 : 1.0\n",
      "               V_tedious = True                0 : 2      =     33.4 : 1.0\n",
      "            V_incredibly = False               4 : 2      =     28.1 : 1.0\n",
      "                  V_year = True                4 : 2      =     28.1 : 1.0\n",
      "                  V_adam = True                0 : 2      =     26.0 : 1.0\n",
      "                  V_care = True                0 : 2      =     26.0 : 1.0\n",
      "                  V_core = True                0 : 2      =     26.0 : 1.0\n",
      "                  V_mess = True                0 : 2      =     26.0 : 1.0\n",
      "                   V_put = True                0 : 2      =     26.0 : 1.0\n",
      "               V_sandler = True                0 : 2      =     26.0 : 1.0\n",
      "                  V_seem = True                0 : 2      =     26.0 : 1.0\n",
      "               V_sitting = True                0 : 2      =     26.0 : 1.0\n",
      "          V_performances = True                4 : 2      =     24.3 : 1.0\n",
      "                 V_still = True                4 : 2      =     24.3 : 1.0\n",
      "                V_beauty = True                4 : 2      =     21.8 : 1.0\n",
      "               V_classic = True                4 : 2      =     21.8 : 1.0\n",
      "              V_deserves = True                4 : 2      =     21.8 : 1.0\n",
      "            V_engrossing = True                4 : 2      =     21.8 : 1.0\n",
      "               V_perfect = True                4 : 2      =     21.8 : 1.0\n",
      "                 V_piece = True                4 : 2      =     21.8 : 1.0\n",
      "            V_production = True                4 : 2      =     21.8 : 1.0\n",
      "                V_subtle = True                4 : 2      =     21.8 : 1.0\n",
      "              V_terrific = True                4 : 2      =     21.8 : 1.0\n",
      "             V_audiences = True                0 : 2      =     20.0 : 1.0\n",
      "                 V_silly = True                0 : 2      =     20.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################### cross-validation for negation ##\n",
    "# this function takes the number of folds, the feature sets\n",
    "# it iterates over the folds, using different sections for training and testing in turn\n",
    "#   it prints the accuracy for each fold and the average accuracy at the end\n",
    "def cross_validation_accuracy(num_folds, NOT_featuresets):\n",
    "    subset_size = int(len(NOT_featuresets)/num_folds)\n",
    "    print('Each fold size:', subset_size)\n",
    "    accuracy_list = []\n",
    "    # iterate over the folds\n",
    "    for i in range(num_folds):\n",
    "        test_this_round = NOT_featuresets[(i*subset_size):][:subset_size]\n",
    "        train_this_round = NOT_featuresets[:(i*subset_size)] + NOT_featuresets[((i+1)*subset_size):]\n",
    "        # train using train_this_round\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_this_round)\n",
    "        # evaluate against test_this_round and save accuracy\n",
    "        accuracy_this_round = nltk.classify.accuracy(classifier, test_this_round)\n",
    "        print (i, accuracy_this_round)\n",
    "        accuracy_list.append(accuracy_this_round)\n",
    "    # find mean accuracy over all rounds\n",
    "    print ('mean accuracy', sum(accuracy_list) / num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each fold size: 1000\n",
      "0 0.529\n",
      "1 0.524\n",
      "2 0.509\n",
      "3 0.521\n",
      "4 0.526\n",
      "5 0.521\n",
      "6 0.524\n",
      "7 0.532\n",
      "8 0.528\n",
      "9 0.502\n",
      "mean accuracy 0.5216000000000001\n"
     ]
    }
   ],
   "source": [
    "# perform the cross-validation on the featuresets with word features and generate accuracy\n",
    "num_folds = 10\n",
    "cross_validation_accuracy(num_folds, NOT_featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "## other evaluation measures:  confusion matrix, precision, recall, F1 ##\n",
    "\n",
    "goldlist = []\n",
    "predictedlist = []\n",
    "for (features, label) in test_set:\n",
    "    \tgoldlist.append(label)\n",
    "    \tpredictedlist.append(classifier.classify(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |    2    3    1    4    0 |\n",
      "--+--------------------------+\n",
      "2 |<1927> 236  207   78   98 |\n",
      "3 |  498 <268>  91  105   97 |\n",
      "1 |  414   64 <228>  39  123 |\n",
      "4 |   75   95   14  <76>  33 |\n",
      "0 |   68   13   78    9  <66>|\n",
      "--+--------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = nltk.ConfusionMatrix(goldlist, predictedlist)\n",
    "print(cm.pretty_format(sort_by_count=True, truncate=9))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |      2      3      1      4      0 |\n",
      "--+------------------------------------+\n",
      "2 | <38.5%>  4.7%   4.1%   1.6%   2.0% |\n",
      "3 |  10.0%  <5.4%>  1.8%   2.1%   1.9% |\n",
      "1 |   8.3%   1.3%  <4.6%>  0.8%   2.5% |\n",
      "4 |   1.5%   1.9%   0.3%  <1.5%>  0.7% |\n",
      "0 |   1.4%   0.3%   1.6%   0.2%  <1.3%>|\n",
      "--+------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# or show the results as percentages\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPrecision\tRecall\t\tF1\n",
      "0 \t      0.282      0.158      0.203\n",
      "1 \t      0.263      0.369      0.307\n",
      "2 \t      0.757      0.646      0.697\n",
      "3 \t      0.253      0.396      0.309\n",
      "4 \t      0.259      0.248      0.253\n"
     ]
    }
   ],
   "source": [
    "# call the function with our data\n",
    "eval_measures(goldlist, predictedlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# POS Classifier #######################################################333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes a document list of words and returns a feature dictionary\n",
    "# it runs the default pos tagger (the Stanford tagger) on the document\n",
    "#   and counts 4 types of pos tags to use as features\n",
    "def POS_features(docs, word_features):\n",
    "    document_words = set(docs)\n",
    "    tagged_words = nltk.pos_tag(docs)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    numNoun = 0\n",
    "    numVerb = 0\n",
    "    numAdj = 0\n",
    "    numAdverb = 0\n",
    "    for (word, tag) in tagged_words:\n",
    "        if tag.startswith('N'): numNoun += 1\n",
    "        if tag.startswith('V'): numVerb += 1\n",
    "        if tag.startswith('J'): numAdj += 1\n",
    "        if tag.startswith('R'): numAdverb += 1\n",
    "    features['nouns'] = numNoun\n",
    "    features['verbs'] = numVerb\n",
    "    features['adjectives'] = numAdj\n",
    "    features['adverbs'] = numAdverb\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1504\n"
     ]
    }
   ],
   "source": [
    "# define feature sets using this function\n",
    "POS_featuresets = [(POS_features(d, word_features), c) for (d, c) in docs]\n",
    "# number of features for document 0\n",
    "print(len(POS_featuresets[0][0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num nouns 1\n",
      "num verbs 0\n",
      "num adjectives 1\n",
      "num adverbs 0\n"
     ]
    }
   ],
   "source": [
    "# the pos tag features for this sentence\n",
    "print('num nouns', POS_featuresets[0][0]['nouns'])\n",
    "print('num verbs', POS_featuresets[0][0]['verbs'])\n",
    "print('num adjectives', POS_featuresets[0][0]['adjectives'])\n",
    "print('num adverbs', POS_featuresets[0][0]['adverbs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test the classifier\n",
    "train_set, test_set = POS_featuresets[5000:], POS_featuresets[:5000]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5252"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################### cross-validation for POS ##\n",
    "# this function takes the number of folds, the feature sets\n",
    "# it iterates over the folds, using different sections for training and testing in turn\n",
    "#   it prints the accuracy for each fold and the average accuracy at the end\n",
    "def cross_validation_accuracy(num_folds, POS_featuresets):\n",
    "    subset_size = int(len(POS_featuresets)/num_folds)\n",
    "    print('Each fold size:', subset_size)\n",
    "    accuracy_list = []\n",
    "    # iterate over the folds\n",
    "    for i in range(num_folds):\n",
    "        test_this_round = POS_featuresets[(i*subset_size):][:subset_size]\n",
    "        train_this_round = POS_featuresets[:(i*subset_size)] + POS_featuresets[((i+1)*subset_size):]\n",
    "        # train using train_this_round\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_this_round)\n",
    "        # evaluate against test_this_round and save accuracy\n",
    "        accuracy_this_round = nltk.classify.accuracy(classifier, test_this_round)\n",
    "        print (i, accuracy_this_round)\n",
    "        accuracy_list.append(accuracy_this_round)\n",
    "    # find mean accuracy over all rounds\n",
    "    print ('mean accuracy', sum(accuracy_list) / num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each fold size: 1000\n",
      "0 0.55\n",
      "1 0.537\n",
      "2 0.529\n",
      "3 0.521\n",
      "4 0.531\n",
      "5 0.526\n",
      "6 0.532\n",
      "7 0.538\n",
      "8 0.536\n",
      "9 0.531\n",
      "mean accuracy 0.5331\n"
     ]
    }
   ],
   "source": [
    "# perform the cross-validation on the featuresets with word features and generate accuracy\n",
    "num_folds = 10\n",
    "cross_validation_accuracy(num_folds, POS_featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "## other evaluation measures:  confusion matrix, precision, recall, F1 ##\n",
    "\n",
    "goldlist = []\n",
    "predictedlist = []\n",
    "for (features, label) in test_set:\n",
    "    \tgoldlist.append(label)\n",
    "    \tpredictedlist.append(classifier.classify(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |    2    3    1    4    0 |\n",
      "--+--------------------------+\n",
      "2 |<2041> 173  227   37   68 |\n",
      "3 |  542 <245> 118   61   93 |\n",
      "1 |  445   77 <229>  17  100 |\n",
      "4 |   89   93   22  <60>  29 |\n",
      "0 |   72   20   88    3  <51>|\n",
      "--+--------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = nltk.ConfusionMatrix(goldlist, predictedlist)\n",
    "print(cm.pretty_format(sort_by_count=True, truncate=9))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |      2      3      1      4      0 |\n",
      "--+------------------------------------+\n",
      "2 | <40.8%>  3.5%   4.5%   0.7%   1.4% |\n",
      "3 |  10.8%  <4.9%>  2.4%   1.2%   1.9% |\n",
      "1 |   8.9%   1.5%  <4.6%>  0.3%   2.0% |\n",
      "4 |   1.8%   1.9%   0.4%  <1.2%>  0.6% |\n",
      "0 |   1.4%   0.4%   1.8%   0.1%  <1.0%>|\n",
      "--+------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# or show the results as percentages\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPrecision\tRecall\t\tF1\n",
      "0 \t      0.218      0.150      0.177\n",
      "1 \t      0.264      0.335      0.295\n",
      "2 \t      0.802      0.640      0.712\n",
      "3 \t      0.231      0.403      0.294\n",
      "4 \t      0.205      0.337      0.255\n"
     ]
    }
   ],
   "source": [
    "# call the function with our data\n",
    "eval_measures(goldlist, predictedlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################### LIWC Sentiment Lexicon for Classifier ########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentiment_read_LIWC_pos_neg_words\n",
    "# initialize positve and negative word prefix lists from LIWC \n",
    "#   note there is another function isPresent to test if a word's prefix is in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "(poslist, neglist) = sentiment_read_LIWC_pos_neg_words.read_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = \"/Users/hub20/SentimentLexicons/liwcdic2007.dic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIWC = read_words(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns two lists:  words in positive emotion class and\n",
    "#\t\t      words in negative emotion class\n",
    "def read_words(path2):\n",
    "  poslist = []\n",
    "  neglist = []\n",
    "\n",
    "  flexicon = open(path2, encoding='latin1')\n",
    "  # read all LIWC words from file\n",
    "  wordlines = [line.strip() for line in flexicon]\n",
    "  # each line has a word or a stem followed by * and numbers of the word classes it is in\n",
    "  # word class 126 is positive emotion and 127 is negative emotion\n",
    "  for line in wordlines:\n",
    "    if not line == '':\n",
    "      items = line.split()\n",
    "      word = items[0]\n",
    "      classes = items[1:]\n",
    "      for c in classes:\n",
    "        if c == '126':\n",
    "          poslist.append( word )\n",
    "        if c == '127':\n",
    "          neglist.append( word )\n",
    "  return (poslist, neglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_words(path2):\n",
    "  poslist = []\n",
    "  neglist = []\n",
    "\n",
    "flexicon = open('SentimentLexicons/liwcdic2007.dic', encoding='latin1')\n",
    "\n",
    "  # read all LIWC words from file\n",
    "\n",
    "wordlines = [line.strip() for line in flexicon]\n",
    "\n",
    "  # each line has a word or a stem followed by * and numbers of the word classes it is in\n",
    "\n",
    "  # word class 126 is positive emotion and 127 is negative emotion\n",
    "\n",
    "  for line in wordlines:\n",
    "\n",
    "    if not line == '':\n",
    "\n",
    "      items = line.split()\n",
    "\n",
    "      word = items[0]\n",
    "\n",
    "      classes = items[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test to see if a word is on the list\n",
    "#   using a prefix test if the word is a stem with an *\n",
    "# returns True or False\n",
    "def isPresent(word, emotionlist):\n",
    "  isFound = False\n",
    "  # loop over all elements of list\n",
    "  for emotionword in emotionlist:\n",
    "    # test if a word or a stem\n",
    "    if not emotionword[-1] == '*':\n",
    "      # it's a word!\n",
    "      # when a match is found, can quit the loop with True\n",
    "      if word == emotionword:\n",
    "        isFound = True\n",
    "        break\n",
    "    else:\n",
    "      # it's a stem!\n",
    "      # when a match is found, can quit the loop with True\n",
    "      if word.startswith(emotionword[0:-1]):\n",
    "        isFound = True\n",
    "        break\n",
    "  # end of loop\n",
    "  return isFound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Words 405 Negative Words 499\n",
      "['accept', 'accepta*', 'accepted', 'accepting', 'accepts', 'active*', 'admir*', 'ador*', 'advantag*', 'adventur*', 'affection*', 'agree', 'agreeab*', 'agreed', 'agreeing', 'agreement*', 'agrees', 'alright*', 'amaz*', 'amor*', 'amus*', 'aok', 'appreciat*', 'assur*', 'attachment*', 'attract*', 'award*', 'awesome', 'beaut*', 'beloved', 'benefic*', 'benefit', 'benefits', 'benefitt*', 'benevolen*', 'benign*', 'best', 'better', 'bless*', 'bold*', 'bonus*', 'brave*', 'bright*', 'brillian*', 'calm*', 'care', 'cared', 'carefree', 'careful*', 'cares', 'caring', 'casual', 'casually', 'certain*', 'challeng*', 'champ*', 'charit*', 'charm*', 'cheer*', 'cherish*', 'chuckl*', 'clever*', 'comed*', 'comfort*', 'commitment*', 'compassion*', 'compliment*', 'confidence', 'confident', 'confidently', 'considerate', 'contented*', 'contentment', 'convinc*', 'cool', 'courag*', 'create*', 'creati*', 'credit*', 'cute*', 'cutie*', 'daring', 'darlin*', 'dear*', 'definite', 'definitely', 'delectabl*', 'delicate*', 'delicious*', 'deligh*', 'determina*', 'determined', 'devot*', 'digni*', 'divin*', 'dynam*', 'eager*', 'ease*', 'easie*', 'easily', 'easiness', 'easing', 'easy*', 'ecsta*', 'efficien*', 'elegan*', 'encourag*', 'energ*', 'engag*', 'enjoy*', 'entertain*', 'enthus*', 'excel*', 'excit*', 'fab', 'fabulous*', 'faith*', 'fantastic*', 'favor*', 'favour*', 'fearless*', 'festiv*', 'fiesta*', 'fine', 'flatter*', 'flawless*', 'flexib*', 'flirt*', 'fond', 'fondly', 'fondness', 'forgave', 'forgiv*', 'free', 'freeb*', 'freed*', 'freeing', 'freely', 'freeness', 'freer', 'frees*', 'friend*', 'fun', 'funn*', 'genero*', 'gentle', 'gentler', 'gentlest', 'gently', 'giggl*', 'giver*', 'giving', 'glad', 'gladly', 'glamor*', 'glamour*', 'glori*', 'glory', 'good', 'goodness', 'gorgeous*', 'grace', 'graced', 'graceful*', 'graces', 'graci*', 'grand', 'grande*', 'gratef*', 'grati*', 'great', 'grin', 'grinn*', 'grins', 'ha', 'haha*', 'handsom*', 'happi*', 'happy', 'harmless*', 'harmon*', 'heartfelt', 'heartwarm*', 'heaven*', 'heh*', 'helper*', 'helpful*', 'helping', 'helps', 'hero*', 'hilarious', 'hoho*', 'honest*', 'honor*', 'honour*', 'hope', 'hoped', 'hopeful', 'hopefully', 'hopefulness', 'hopes', 'hoping', 'hug', 'hugg*', 'hugs', 'humor*', 'humour*', 'hurra*', 'ideal*', 'importan*', 'impress*', 'improve*', 'improving', 'incentive*', 'innocen*', 'inspir*', 'intell*', 'interest*', 'invigor*', 'joke*', 'joking', 'joll*', 'joy*', 'keen*', 'kidding', 'kindly', 'kindn*', 'kiss*', 'laidback', 'laugh*', 'libert*', 'likeab*', 'liked', 'likes', 'liking', 'livel*', 'lmao', 'lol', 'love', 'loved', 'lovely', 'lover*', 'loves', 'loving*', 'loyal*', 'luck', 'lucked', 'lucki*', 'lucks', 'lucky', 'madly', 'magnific*', 'merit*', 'merr*', 'neat*', 'nice*', 'nurtur*', 'ok', 'okay', 'okays', 'oks', 'openminded*', 'openness', 'opport*', 'optimal*', 'optimi*', 'original', 'outgoing', 'painl*', 'palatabl*', 'paradise', 'partie*', 'party*', 'passion*', 'peace*', 'perfect*', 'play', 'played', 'playful*', 'playing', 'plays', 'pleasant*', 'please*', 'pleasing', 'pleasur*', 'popular*', 'positiv*', 'prais*', 'precious*', 'prettie*', 'pretty', 'pride', 'privileg*', 'prize*', 'profit*', 'promis*', 'proud*', 'radian*', 'readiness', 'ready', 'reassur*', 'relax*', 'relief', 'reliev*', 'resolv*', 'respect', 'revigor*', 'reward*', 'rich*', 'rofl', 'romanc*', 'romantic*', 'safe*', 'satisf*', 'save', 'scrumptious*', 'secur*', 'sentimental*', 'share', 'shared', 'shares', 'sharing', 'silli*', 'silly', 'sincer*', 'smart*', 'smil*', 'sociab*', 'soulmate*', 'special', 'splend*', 'strength*', 'strong*', 'succeed*', 'success*', 'sunnier', 'sunniest', 'sunny', 'sunshin*', 'super', 'superior*', 'support', 'supported', 'supporter*', 'supporting', 'supportive*', 'supports', 'suprem*', 'sure*', 'surpris*', 'sweet', 'sweetheart*', 'sweetie*', 'sweetly', 'sweetness*', 'sweets', 'talent*', 'tehe', 'tender*', 'terrific*', 'thank', 'thanked', 'thankf*', 'thanks', 'thoughtful*', 'thrill*', 'toleran*', 'tranquil*', 'treasur*', 'treat', 'triumph*', 'true', 'trueness', 'truer', 'truest', 'truly', 'trust*', 'truth*', 'useful*', 'valuabl*', 'value', 'valued', 'values', 'valuing', 'vigor*', 'vigour*', 'virtue*', 'virtuo*', 'vital*', 'warm*', 'wealth*', 'welcom*', 'well', 'win', 'winn*', 'wins', 'wisdom', 'wise*', 'won', 'wonderf*', 'worship*', 'worthwhile', 'wow*', 'yay', 'yays']\n",
      "['abandon*', 'abuse*', 'abusi*', 'ache*', 'aching', 'advers*', 'afraid', 'aggravat*', 'aggress*', 'agitat*', 'agoniz*', 'agony', 'alarm*', 'alone', 'anger*', 'angr*', 'anguish*', 'annoy*', 'antagoni*', 'anxi*', 'apath*', 'appall*', 'apprehens*', 'argh*', 'argu*', 'arrogan*', 'asham*', 'assault*', 'asshole*', 'attack*', 'aversi*', 'avoid*', 'awful', 'awkward*', 'bad', 'bashful*', 'bastard*', 'battl*', 'beaten', 'bitch*', 'bitter*', 'blam*', 'bore*', 'boring', 'bother*', 'broke', 'brutal*', 'burden*', 'careless*', 'cheat*', 'complain*', 'confront*', 'confus*', 'contempt*', 'contradic*', 'crap', 'crappy', 'craz*', 'cried', 'cries', 'critical', 'critici*', 'crude*', 'cruel*', 'crushed', 'cry', 'crying', 'cunt*', 'cut', 'cynic', 'damag*', 'damn*', 'danger*', 'daze*', 'decay*', 'defeat*', 'defect*', 'defenc*', 'defens*', 'degrad*', 'depress*', 'depriv*', 'despair*', 'desperat*', 'despis*', 'destroy*', 'destruct*', 'devastat*', 'devil*', 'difficult*', 'disadvantage*', 'disagree*', 'disappoint*', 'disaster*', 'discomfort*', 'discourag*', 'disgust*', 'dishearten*', 'disillusion*', 'dislike', 'disliked', 'dislikes', 'disliking', 'dismay*', 'dissatisf*', 'distract*', 'distraught', 'distress*', 'distrust*', 'disturb*', 'domina*', 'doom*', 'dork*', 'doubt*', 'dread*', 'dull*', 'dumb*', 'dump*', 'dwell*', 'egotis*', 'embarrass*', 'emotional', 'empt*', 'enemie*', 'enemy*', 'enrag*', 'envie*', 'envious', 'envy*', 'evil*', 'excruciat*', 'exhaust*', 'fail*', 'fake', 'fatal*', 'fatigu*', 'fault*', 'fear', 'feared', 'fearful*', 'fearing', 'fears', 'feroc*', 'feud*', 'fiery', 'fight*', 'fired', 'flunk*', 'foe*', 'fool*', 'forbid*', 'fought', 'frantic*', 'freak*', 'fright*', 'frustrat*', 'fuck', 'fucked*', 'fucker*', 'fuckin*', 'fucks', 'fume*', 'fuming', 'furious*', 'fury', 'geek*', 'gloom*', 'goddam*', 'gossip*', 'grave*', 'greed*', 'grief', 'griev*', 'grim*', 'gross*', 'grouch*', 'grr*', 'guilt*', 'harass*', 'harm', 'harmed', 'harmful*', 'harming', 'harms', 'hate', 'hated', 'hateful*', 'hater*', 'hates', 'hating', 'hatred', 'heartbreak*', 'heartbroke*', 'heartless*', 'hell', 'hellish', 'helpless*', 'hesita*', 'homesick*', 'hopeless*', 'horr*', 'hostil*', 'humiliat*', 'hurt*', 'idiot*', 'ignor*', 'immoral*', 'impatien*', 'impersonal', 'impolite*', 'inadequa*', 'indecis*', 'ineffect*', 'inferior*', 'inhib*', 'insecur*', 'insincer*', 'insult*', 'interrup*', 'intimidat*', 'irrational*', 'irrita*', 'isolat*', 'jaded', 'jealous*', 'jerk', 'jerked', 'jerks', 'kill*', 'lame*', 'lazie*', 'lazy', 'liabilit*', 'liar*', 'lied', 'lies', 'lone*', 'longing*', 'lose', 'loser*', 'loses', 'losing', 'loss*', 'lost', 'lous*', 'low*', 'luckless*', 'ludicrous*', 'lying', 'mad', 'maddening', 'madder', 'maddest', 'maniac*', 'masochis*', 'melanchol*', 'mess', 'messy', 'miser*', 'miss', 'missed', 'misses', 'missing', 'mistak*', 'mock', 'mocked', 'mocker*', 'mocking', 'mocks', 'molest*', 'mooch*', 'moodi*', 'moody', 'moron*', 'mourn*', 'murder*', 'nag*', 'nast*', 'needy', 'neglect*', 'nerd*', 'nervous*', 'neurotic*', 'numb*', 'obnoxious*', 'obsess*', 'offence*', 'offend*', 'offens*', 'outrag*', 'overwhelm*', 'pain', 'pained', 'painf*', 'paining', 'pains', 'panic*', 'paranoi*', 'pathetic*', 'peculiar*', 'perver*', 'pessimis*', 'petrif*', 'pettie*', 'petty*', 'phobi*', 'piss*', 'piti*', 'pity*', 'poison*', 'prejudic*', 'pressur*', 'prick*', 'problem*', 'protest', 'protested', 'protesting', 'puk*', 'punish*', 'rage*', 'raging', 'rancid*', 'rape*', 'raping', 'rapist*', 'rebel*', 'reek*', 'regret*', 'reject*', 'reluctan*', 'remorse*', 'repress*', 'resent*', 'resign*', 'restless*', 'revenge*', 'ridicul*', 'rigid*', 'risk*', 'rotten', 'rude*', 'ruin*', 'sad', 'sadde*', 'sadly', 'sadness', 'sarcas*', 'savage*', 'scare*', 'scaring', 'scary', 'sceptic*', 'scream*', 'screw*', 'selfish*', 'serious', 'seriously', 'seriousness', 'severe*', 'shake*', 'shaki*', 'shaky', 'shame*', 'shit*', 'shock*', 'shook', 'shy*', 'sicken*', 'sin', 'sinister', 'sins', 'skeptic*', 'slut*', 'smother*', 'smug*', 'snob*', 'sob', 'sobbed', 'sobbing', 'sobs', 'solemn*', 'sorrow*', 'sorry', 'spite*', 'stammer*', 'stank', 'startl*', 'steal*', 'stench*', 'stink*', 'strain*', 'strange', 'stress*', 'struggl*', 'stubborn*', 'stunk', 'stunned', 'stuns', 'stupid*', 'stutter*', 'submissive*', 'suck', 'sucked', 'sucker*', 'sucks', 'sucky', 'suffer', 'suffered', 'sufferer*', 'suffering', 'suffers', 'suspicio*', 'tantrum*', 'tears', 'teas*', 'temper', 'tempers', 'tense*', 'tensing', 'tension*', 'terribl*', 'terrified', 'terrifies', 'terrify', 'terrifying', 'terror*', 'thief', 'thieve*', 'threat*', 'ticked', 'timid*', 'tortur*', 'tough*', 'traged*', 'tragic*', 'trauma*', 'trembl*', 'trick*', 'trite', 'trivi*', 'troubl*', 'turmoil', 'ugh', 'ugl*', 'unattractive', 'uncertain*', 'uncomfortabl*', 'uncontrol*', 'uneas*', 'unfortunate*', 'unfriendly', 'ungrateful*', 'unhapp*', 'unimportant', 'unimpress*', 'unkind', 'unlov*', 'unpleasant', 'unprotected', 'unsavo*', 'unsuccessful*', 'unsure*', 'unwelcom*', 'upset*', 'uptight*', 'useless*', 'vain', 'vanity', 'vicious*', 'victim*', 'vile', 'villain*', 'violat*', 'violent*', 'vulnerab*', 'vulture*', 'war', 'warfare*', 'warred', 'warring', 'wars', 'weak*', 'weapon*', 'weep*', 'weird*', 'wept', 'whine*', 'whining', 'whore*', 'wicked*', 'wimp*', 'witch', 'woe*', 'worr*', 'worse*', 'worst', 'worthless*', 'wrong*', 'yearn*']\n",
      "ache False True\n",
      "crashed False False\n",
      "worsen False True\n",
      "worthless False True\n",
      "nice True False\n",
      "better True False\n"
     ]
    }
   ],
   "source": [
    "# for testing purposes, run the file with no command line arguments\n",
    "# the main prints all positive and negative words\n",
    "# and tests some words <<<<<<<________ look at this Ken!!!\n",
    "if __name__=='__main__':\n",
    "  (poslist, neglist) = read_words()\n",
    "  print (\"Positive Words\", len(poslist), \"Negative Words\", len(neglist))\n",
    "  print (poslist)\n",
    "  print (neglist)\n",
    "  words = ['ache', 'crashed', 'worsen', 'worthless', 'nice', 'better']\n",
    "  for word in words:\n",
    "    print (word, isPresent(word, poslist), isPresent(word, neglist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LIWC_features(docs, word_features, LIWC):\n",
    "    document_words = set(docs)\n",
    "    LIWC_words = read_words(path2)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['V_{}'.format(word)] = (word in document_words)\n",
    "    # count variables for the 2 classes of subjectivity\n",
    "    Pos = 0\n",
    "    Neg = 0\n",
    "    for word in LIWC_words:\n",
    "        if word in LIWC:\n",
    "            classes = LIWC[word]\n",
    "            if classes == '126':\n",
    "                Pos += 1\n",
    "            if classes == '125':\n",
    "                Neg += 1\n",
    "    features['positivecount'] = Pos\n",
    "    features['negativecount'] = Neg     \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'V_the': True,\n",
       "  'V_,': False,\n",
       "  'V_a': False,\n",
       "  'V_of': True,\n",
       "  'V_and': True,\n",
       "  'V_to': False,\n",
       "  'V_.': True,\n",
       "  \"V_'s\": False,\n",
       "  'V_in': True,\n",
       "  'V_is': False,\n",
       "  'V_that': False,\n",
       "  'V_it': False,\n",
       "  'V_as': False,\n",
       "  'V_for': False,\n",
       "  'V_with': False,\n",
       "  'V_an': False,\n",
       "  'V_its': False,\n",
       "  'V_film': False,\n",
       "  'V_this': False,\n",
       "  'V_movie': False,\n",
       "  'V_but': False,\n",
       "  'V_you': False,\n",
       "  'V_be': False,\n",
       "  'V_on': False,\n",
       "  'V_by': False,\n",
       "  'V_about': False,\n",
       "  'V_not': False,\n",
       "  'V_more': False,\n",
       "  'V_one': False,\n",
       "  'V_at': False,\n",
       "  'V_``': False,\n",
       "  'V_his': False,\n",
       "  'V_or': False,\n",
       "  'V_all': False,\n",
       "  \"V_n't\": False,\n",
       "  'V_than': False,\n",
       "  'V_--': False,\n",
       "  'V_from': False,\n",
       "  'V_are': True,\n",
       "  'V_like': False,\n",
       "  'V_has': False,\n",
       "  \"V_'\": False,\n",
       "  'V_have': False,\n",
       "  'V_who': False,\n",
       "  'V_most': False,\n",
       "  'V_out': False,\n",
       "  'V_-rrb-': False,\n",
       "  'V_story': False,\n",
       "  'V_characters': False,\n",
       "  'V_into': False,\n",
       "  'V_up': False,\n",
       "  'V_time': False,\n",
       "  'V_so': False,\n",
       "  'V_good': False,\n",
       "  'V_too': False,\n",
       "  'V_-lrb-': False,\n",
       "  'V_`': False,\n",
       "  'V_no': False,\n",
       "  'V_their': False,\n",
       "  'V_much': False,\n",
       "  'V_if': False,\n",
       "  'V_what': False,\n",
       "  'V_does': False,\n",
       "  'V_...': False,\n",
       "  'V_some': False,\n",
       "  'V_little': False,\n",
       "  'V_only': False,\n",
       "  'V_any': False,\n",
       "  'V_director': False,\n",
       "  'V_even': False,\n",
       "  'V_way': False,\n",
       "  'V_comedy': False,\n",
       "  'V_been': False,\n",
       "  'V_i': False,\n",
       "  'V_will': False,\n",
       "  'V_which': False,\n",
       "  'V_life': False,\n",
       "  'V_he': False,\n",
       "  'V_movies': False,\n",
       "  'V_funny': False,\n",
       "  'V_something': False,\n",
       "  'V_there': False,\n",
       "  'V_your': False,\n",
       "  'V_was': False,\n",
       "  'V_when': False,\n",
       "  'V_can': False,\n",
       "  'V_make': False,\n",
       "  'V_her': False,\n",
       "  'V_do': False,\n",
       "  'V_them': False,\n",
       "  'V_makes': False,\n",
       "  'V_love': False,\n",
       "  'V_enough': False,\n",
       "  'V_two': False,\n",
       "  'V_own': False,\n",
       "  'V_us': False,\n",
       "  'V_made': False,\n",
       "  'V_work': False,\n",
       "  'V_action': False,\n",
       "  'V_bad': False,\n",
       "  'V_many': False,\n",
       "  'V_being': False,\n",
       "  'V_may': False,\n",
       "  'V_feel': False,\n",
       "  'V_very': False,\n",
       "  'V_they': False,\n",
       "  'V_better': False,\n",
       "  'V_we': False,\n",
       "  'V_see': False,\n",
       "  'V_never': False,\n",
       "  'V_plot': False,\n",
       "  'V_while': False,\n",
       "  'V_new': False,\n",
       "  'V_other': False,\n",
       "  'V_just': False,\n",
       "  'V_those': False,\n",
       "  'V_would': False,\n",
       "  'V_well': False,\n",
       "  'V_best': False,\n",
       "  'V_humor': True,\n",
       "  'V_had': False,\n",
       "  'V_off': False,\n",
       "  'V_ever': False,\n",
       "  'V_character': False,\n",
       "  \"V_'re\": False,\n",
       "  'V_without': False,\n",
       "  'V_look': False,\n",
       "  'V_emotional': False,\n",
       "  'V_big': False,\n",
       "  'V_still': False,\n",
       "  'V_films': False,\n",
       "  'V_world': False,\n",
       "  'V_hollywood': False,\n",
       "  'V_real': False,\n",
       "  'V_come': False,\n",
       "  'V_audience': False,\n",
       "  'V_could': False,\n",
       "  'V_how': False,\n",
       "  'V_cast': False,\n",
       "  'V_performances': False,\n",
       "  'V_people': False,\n",
       "  'V_minutes': False,\n",
       "  'V_through': False,\n",
       "  'V_old': False,\n",
       "  'V_:': False,\n",
       "  'V_man': False,\n",
       "  'V_really': False,\n",
       "  'V_both': False,\n",
       "  'V_nothing': False,\n",
       "  'V_subject': False,\n",
       "  'V_performance': False,\n",
       "  'V_find': False,\n",
       "  'V_great': False,\n",
       "  'V_first': False,\n",
       "  'V_kind': False,\n",
       "  'V_another': False,\n",
       "  'V_drama': False,\n",
       "  'V_also': False,\n",
       "  'V_over': False,\n",
       "  'V_before': False,\n",
       "  'V_were': False,\n",
       "  'V_music': False,\n",
       "  'V_sometimes': False,\n",
       "  'V_every': False,\n",
       "  'V_because': False,\n",
       "  'V_sense': False,\n",
       "  'V_less': False,\n",
       "  'V_down': False,\n",
       "  'V_here': False,\n",
       "  'V_material': False,\n",
       "  'V_seems': False,\n",
       "  'V_almost': False,\n",
       "  'V_between': False,\n",
       "  'V_dialogue': False,\n",
       "  'V_should': False,\n",
       "  'V_long': False,\n",
       "  'V_american': False,\n",
       "  'V_give': False,\n",
       "  'V_things': False,\n",
       "  'V_scenes': False,\n",
       "  'V_human': False,\n",
       "  'V_script': False,\n",
       "  'V_my': False,\n",
       "  'V_year': False,\n",
       "  'V_often': False,\n",
       "  'V_rather': False,\n",
       "  'V_these': False,\n",
       "  'V_fun': False,\n",
       "  'V_actors': False,\n",
       "  'V_entertaining': False,\n",
       "  'V_hard': False,\n",
       "  'V_entertainment': False,\n",
       "  'V_thriller': False,\n",
       "  'V_our': False,\n",
       "  'V_history': False,\n",
       "  'V_right': False,\n",
       "  'V_original': False,\n",
       "  'V_works': False,\n",
       "  'V_quite': False,\n",
       "  'V_him': False,\n",
       "  'V_watching': False,\n",
       "  'V_such': False,\n",
       "  'V_-': False,\n",
       "  'V_back': False,\n",
       "  'V_cinema': False,\n",
       "  'V_heart': False,\n",
       "  'V_get': False,\n",
       "  'V_few': False,\n",
       "  'V_moments': False,\n",
       "  'V_acting': False,\n",
       "  'V_pretty': False,\n",
       "  'V_series': False,\n",
       "  'V_seem': False,\n",
       "  'V_screen': False,\n",
       "  'V_know': False,\n",
       "  'V_place': False,\n",
       "  'V_romantic': False,\n",
       "  'V_take': False,\n",
       "  'V_comes': False,\n",
       "  'V_family': False,\n",
       "  'V_need': False,\n",
       "  'V_once': False,\n",
       "  'V_watch': False,\n",
       "  'V_care': False,\n",
       "  'V_though': False,\n",
       "  'V_matter': False,\n",
       "  'V_interesting': False,\n",
       "  'V_familiar': False,\n",
       "  'V_offers': False,\n",
       "  'V_young': False,\n",
       "  'V_thing': False,\n",
       "  'V_star': False,\n",
       "  'V_full': False,\n",
       "  'V_anyone': False,\n",
       "  'V_documentary': False,\n",
       "  'V_go': False,\n",
       "  'V_fans': False,\n",
       "  'V_anything': False,\n",
       "  \"V_'ve\": False,\n",
       "  'V_after': False,\n",
       "  'V_always': False,\n",
       "  'V_years': False,\n",
       "  'V_show': False,\n",
       "  'V_lot': False,\n",
       "  'V_tale': False,\n",
       "  'V_going': False,\n",
       "  'V_me': False,\n",
       "  'V_culture': False,\n",
       "  'V_seen': False,\n",
       "  'V_worth': False,\n",
       "  'V_book': False,\n",
       "  'V_keep': False,\n",
       "  'V_dull': False,\n",
       "  'V_comic': False,\n",
       "  'V_feels': False,\n",
       "  'V_yet': False,\n",
       "  'V_piece': False,\n",
       "  'V_style': False,\n",
       "  'V_;': False,\n",
       "  'V_cold': False,\n",
       "  'V_idea': False,\n",
       "  'V_set': False,\n",
       "  'V_special': False,\n",
       "  'V_war': False,\n",
       "  'V_same': False,\n",
       "  'V_three': False,\n",
       "  'V_genre': False,\n",
       "  'V_silly': False,\n",
       "  'V_end': False,\n",
       "  'V_away': False,\n",
       "  'V_worst': False,\n",
       "  'V_sequel': False,\n",
       "  'V_fresh': False,\n",
       "  'V_might': False,\n",
       "  'V_picture': False,\n",
       "  'V_premise': False,\n",
       "  'V_around': False,\n",
       "  'V_easy': False,\n",
       "  'V_part': False,\n",
       "  'V_flick': False,\n",
       "  'V_effects': False,\n",
       "  'V_death': False,\n",
       "  'V_gets': False,\n",
       "  'V_whose': False,\n",
       "  'V_why': False,\n",
       "  'V_visual': False,\n",
       "  'V_bit': False,\n",
       "  'V_art': False,\n",
       "  'V_say': False,\n",
       "  'V_making': False,\n",
       "  'V_done': False,\n",
       "  'V_did': False,\n",
       "  'V_sweet': False,\n",
       "  'V_men': False,\n",
       "  'V_himself': False,\n",
       "  'V_think': False,\n",
       "  \"V_'d\": False,\n",
       "  'V_looking': False,\n",
       "  'V_horror': False,\n",
       "  'V_true': False,\n",
       "  'V_cinematic': False,\n",
       "  'V_last': False,\n",
       "  'V_flat': False,\n",
       "  'V_takes': False,\n",
       "  'V_again': False,\n",
       "  \"V_'ll\": False,\n",
       "  'V_contrived': False,\n",
       "  'V_laughs': False,\n",
       "  'V_children': False,\n",
       "  'V_study': False,\n",
       "  'V_half': False,\n",
       "  'V_lives': False,\n",
       "  'V_modern': False,\n",
       "  'V_nearly': False,\n",
       "  'V_ca': False,\n",
       "  'V_far': False,\n",
       "  'V_times': False,\n",
       "  'V_smart': False,\n",
       "  'V_powerful': False,\n",
       "  'V_amusing': False,\n",
       "  'V_next': False,\n",
       "  'V_black': False,\n",
       "  'V_tone': False,\n",
       "  'V_each': False,\n",
       "  'V_instead': False,\n",
       "  'V_feeling': False,\n",
       "  'V_ending': False,\n",
       "  'V_past': False,\n",
       "  'V_screenplay': False,\n",
       "  'V_gives': False,\n",
       "  'V_want': False,\n",
       "  'V_short': False,\n",
       "  'V_high': False,\n",
       "  'V_especially': False,\n",
       "  'V_dark': False,\n",
       "  'V_summer': False,\n",
       "  'V_trying': False,\n",
       "  'V_simply': False,\n",
       "  'V_elements': False,\n",
       "  'V_direction': False,\n",
       "  'V_?': False,\n",
       "  'V_suspense': False,\n",
       "  'V_role': False,\n",
       "  'V_moving': False,\n",
       "  'V_itself': False,\n",
       "  'V_reason': False,\n",
       "  'V_james': False,\n",
       "  'V_face': False,\n",
       "  'V_leave': False,\n",
       "  'V_kids': False,\n",
       "  'V_classic': False,\n",
       "  'V_exercise': False,\n",
       "  'V_debut': False,\n",
       "  'V_completely': False,\n",
       "  'V_memorable': False,\n",
       "  'V_dramatic': False,\n",
       "  'V_probably': False,\n",
       "  'V_version': False,\n",
       "  'V_filmmakers': False,\n",
       "  'V_woman': False,\n",
       "  'V_filmmaking': False,\n",
       "  'V_since': False,\n",
       "  'V_laugh': False,\n",
       "  'V_together': False,\n",
       "  'V_power': False,\n",
       "  'V_fascinating': False,\n",
       "  'V_else': False,\n",
       "  'V_quality': False,\n",
       "  'V_found': False,\n",
       "  'V_french': False,\n",
       "  'V_least': False,\n",
       "  'V_women': False,\n",
       "  'V_soap': False,\n",
       "  'V_guy': False,\n",
       "  'V_wit': False,\n",
       "  'V_home': False,\n",
       "  'V_camera': False,\n",
       "  'V_whole': False,\n",
       "  'V_de': False,\n",
       "  'V_written': False,\n",
       "  'V_experience': False,\n",
       "  'V_viewers': False,\n",
       "  'V_hour': False,\n",
       "  'V_themselves': False,\n",
       "  'V_simple': False,\n",
       "  'V_rich': False,\n",
       "  'V_brilliant': False,\n",
       "  'V_turn': False,\n",
       "  'V_compelling': False,\n",
       "  'V_intelligence': False,\n",
       "  'V_sad': False,\n",
       "  'V_talent': False,\n",
       "  'V_playing': False,\n",
       "  'V_michael': False,\n",
       "  'V_light': False,\n",
       "  'V_john': False,\n",
       "  'V_dumb': False,\n",
       "  'V_video': False,\n",
       "  'V_message': False,\n",
       "  'V_audiences': False,\n",
       "  'V_day': False,\n",
       "  'V_romance': False,\n",
       "  'V_under': False,\n",
       "  'V_honest': False,\n",
       "  'V_working': False,\n",
       "  'V_viewer': False,\n",
       "  'V_images': False,\n",
       "  'V_!': False,\n",
       "  'V_creative': False,\n",
       "  'V_hand': False,\n",
       "  'V_spirit': False,\n",
       "  'V_narrative': False,\n",
       "  'V_ultimately': False,\n",
       "  'V_sophisticated': False,\n",
       "  'V_lost': False,\n",
       "  'V_tragedy': False,\n",
       "  'V_worthy': False,\n",
       "  'V_taken': False,\n",
       "  \"V_'m\": False,\n",
       "  'V_approach': False,\n",
       "  'V_sci-fi': False,\n",
       "  'V_girl': False,\n",
       "  'V_conclusion': False,\n",
       "  'V_remarkable': False,\n",
       "  'V_situation': False,\n",
       "  'V_eyes': False,\n",
       "  'V_surprising': False,\n",
       "  'V_must': False,\n",
       "  'V_quirky': False,\n",
       "  'V_\\\\': False,\n",
       "  'V_*': False,\n",
       "  'V_appeal': False,\n",
       "  'V_side': False,\n",
       "  'V_satisfying': False,\n",
       "  'V_certainly': False,\n",
       "  'V_offer': False,\n",
       "  'V_insight': False,\n",
       "  'V_grant': False,\n",
       "  'V_animation': False,\n",
       "  'V_point': False,\n",
       "  'V_feature': False,\n",
       "  'V_endless': False,\n",
       "  'V_reality': False,\n",
       "  'V_then': False,\n",
       "  'V_deeply': False,\n",
       "  'V_white': False,\n",
       "  'V_mess': False,\n",
       "  'V_particularly': False,\n",
       "  'V_whatever': False,\n",
       "  'V_clever': False,\n",
       "  'V_none': False,\n",
       "  'V_serious': False,\n",
       "  'V_tell': False,\n",
       "  'V_formula': False,\n",
       "  'V_either': False,\n",
       "  'V_important': False,\n",
       "  'V_portrait': False,\n",
       "  'V_stuff': False,\n",
       "  'V_father': False,\n",
       "  'V_inspired': False,\n",
       "  'V_put': False,\n",
       "  'V_hero': False,\n",
       "  'V_project': False,\n",
       "  'V_keeps': False,\n",
       "  'V_beyond': False,\n",
       "  'V_play': False,\n",
       "  'V_opera': False,\n",
       "  'V_change': False,\n",
       "  'V_level': False,\n",
       "  'V_engaging': False,\n",
       "  'V_ms.': False,\n",
       "  'V_obvious': False,\n",
       "  'V_passion': False,\n",
       "  'V_shot': False,\n",
       "  'V_seeing': False,\n",
       "  'V_truly': False,\n",
       "  'V_cut': False,\n",
       "  'V_left': False,\n",
       "  'V_plenty': False,\n",
       "  'V_sort': False,\n",
       "  'V_title': False,\n",
       "  'V_everyone': False,\n",
       "  'V_energy': False,\n",
       "  'V_along': False,\n",
       "  'V_got': False,\n",
       "  'V_boy': False,\n",
       "  'V_questions': False,\n",
       "  'V_job': False,\n",
       "  'V_mr.': False,\n",
       "  'V_intelligent': False,\n",
       "  'V_vision': False,\n",
       "  'V_filmmaker': False,\n",
       "  'V_based': False,\n",
       "  'V_social': False,\n",
       "  'V_performers': False,\n",
       "  'V_deal': False,\n",
       "  'V_soul': False,\n",
       "  'V_bullock': False,\n",
       "  'V_creepy': False,\n",
       "  'V_thought': False,\n",
       "  'V_certain': False,\n",
       "  'V_add': False,\n",
       "  'V_close': False,\n",
       "  'V_inside': False,\n",
       "  'V_desire': False,\n",
       "  'V_supposed': False,\n",
       "  'V_money': False,\n",
       "  'V_trip': False,\n",
       "  'V_thinking': False,\n",
       "  'V_given': False,\n",
       "  'V_turns': False,\n",
       "  'V_revealing': False,\n",
       "  'V_house': False,\n",
       "  'V_lack': False,\n",
       "  'V_parents': False,\n",
       "  'V_solid': False,\n",
       "  'V_cliches': False,\n",
       "  'V_likely': False,\n",
       "  'V_lacking': False,\n",
       "  'V_actually': False,\n",
       "  'V_magic': False,\n",
       "  'V_goes': False,\n",
       "  'V_everything': False,\n",
       "  'V_disney': False,\n",
       "  'V_mind': False,\n",
       "  'V_stock': False,\n",
       "  'V_comedies': False,\n",
       "  'V_points': False,\n",
       "  'V_terrible': False,\n",
       "  'V_chan': False,\n",
       "  'V_whether': False,\n",
       "  'V_pace': False,\n",
       "  'V_getting': False,\n",
       "  'V_emotion': False,\n",
       "  'V_stand': False,\n",
       "  'V_boring': False,\n",
       "  'V_rare': False,\n",
       "  'V_nature': False,\n",
       "  'V_lacks': False,\n",
       "  'V_mystery': False,\n",
       "  'V_stories': False,\n",
       "  'V_90': False,\n",
       "  'V_sandler': False,\n",
       "  'V_fact': False,\n",
       "  'V_impact': False,\n",
       "  'V_sentimental': False,\n",
       "  'V_recent': False,\n",
       "  'V_con': False,\n",
       "  'V_room': False,\n",
       "  'V_enjoyable': False,\n",
       "  'V_adventure': False,\n",
       "  'V_poor': False,\n",
       "  'V_events': False,\n",
       "  'V_looks': False,\n",
       "  'V_use': False,\n",
       "  'V_small': False,\n",
       "  'V_becomes': False,\n",
       "  'V_previous': False,\n",
       "  'V_friendship': False,\n",
       "  'V_now': False,\n",
       "  'V_perfect': True,\n",
       "  'V_nice': False,\n",
       "  'V_sexual': False,\n",
       "  'V_ways': False,\n",
       "  'V_live': False,\n",
       "  'V_secrets': False,\n",
       "  'V_view': False,\n",
       "  'V_mood': False,\n",
       "  'V_teen': False,\n",
       "  'V_funnier': False,\n",
       "  'V_age': False,\n",
       "  'V_night': False,\n",
       "  'V_attempt': False,\n",
       "  'V_wild': False,\n",
       "  'V_mixed': False,\n",
       "  'V_expect': False,\n",
       "  'V_felt': False,\n",
       "  'V_question': False,\n",
       "  'V_ensemble': False,\n",
       "  'V_damned': False,\n",
       "  'V_historical': False,\n",
       "  'V_period': False,\n",
       "  'V_bond': False,\n",
       "  'V_particular': False,\n",
       "  'V_running': False,\n",
       "  'V_strange': False,\n",
       "  'V_hilarious': False,\n",
       "  'V_four': False,\n",
       "  'V_having': False,\n",
       "  'V_talking': False,\n",
       "  'V_theater': False,\n",
       "  'V_dog': False,\n",
       "  'V_strangely': False,\n",
       "  'V_crazy': False,\n",
       "  'V_process': False,\n",
       "  'V_witty': False,\n",
       "  'V_goofy': False,\n",
       "  'V_novel': False,\n",
       "  'V_car': False,\n",
       "  'V_actor': False,\n",
       "  'V_gags': False,\n",
       "  'V_relationships': False,\n",
       "  'V_intellectual': False,\n",
       "  'V_behavior': False,\n",
       "  'V_watchable': False,\n",
       "  'V_easily': False,\n",
       "  'V_taste': False,\n",
       "  'V_storytelling': False,\n",
       "  'V_sustain': False,\n",
       "  'V_fairly': False,\n",
       "  'V_sight': False,\n",
       "  'V_utterly': False,\n",
       "  'V_cartoon': False,\n",
       "  'V_entire': False,\n",
       "  'V_ambitious': False,\n",
       "  'V_journey': False,\n",
       "  'V_interest': False,\n",
       "  'V_gay': False,\n",
       "  'V_crime': False,\n",
       "  'V_knows': False,\n",
       "  'V_holes': False,\n",
       "  'V_mainstream': False,\n",
       "  'V_concept': False,\n",
       "  'V_wanted': False,\n",
       "  'V_act': False,\n",
       "  'V_predictable': False,\n",
       "  'V_pleasure': False,\n",
       "  'V_truth': False,\n",
       "  'V_deserves': False,\n",
       "  'V_winning': False,\n",
       "  'V_admirable': False,\n",
       "  'V_pay': False,\n",
       "  'V_guys': False,\n",
       "  'V_die': False,\n",
       "  'V_break': False,\n",
       "  'V_unsettling': False,\n",
       "  'V_wonderful': False,\n",
       "  'V_low': False,\n",
       "  'V_pictures': False,\n",
       "  'V_slow': False,\n",
       "  'V_jokes': False,\n",
       "  'V_answers': False,\n",
       "  'V_finds': False,\n",
       "  'V_intriguing': False,\n",
       "  'V_engrossing': False,\n",
       "  'V_strong': False,\n",
       "  'V_occasionally': False,\n",
       "  'V_fine': False,\n",
       "  'V_melodrama': False,\n",
       "  'V_seagal': False,\n",
       "  'V_imagination': False,\n",
       "  'V_political': False,\n",
       "  'V_genuine': False,\n",
       "  'V_sure': False,\n",
       "  'V_\\\\/': False,\n",
       "  'V_pop': False,\n",
       "  'V_enjoy': False,\n",
       "  'V_balance': True,\n",
       "  'V_intentions': False,\n",
       "  'V_violence': False,\n",
       "  'V_considerable': False,\n",
       "  'V_ford': False,\n",
       "  'V_sounds': False,\n",
       "  'V_believe': False,\n",
       "  'V_production': False,\n",
       "  'V_waste': False,\n",
       "  'V_pieces': False,\n",
       "  'V_amount': False,\n",
       "  'V_despite': False,\n",
       "  'V_charm': False,\n",
       "  'V_allows': False,\n",
       "  'V_otherwise': False,\n",
       "  'V_signs': False,\n",
       "  'V_warm': False,\n",
       "  'V_moral': False,\n",
       "  'V_fire': False,\n",
       "  'V_deep': False,\n",
       "  'V_career': False,\n",
       "  'V_paper': False,\n",
       "  'V_nor': False,\n",
       "  'V_involving': False,\n",
       "  'V_delivers': False,\n",
       "  'V_evil': False,\n",
       "  'V_wife': False,\n",
       "  'V_game': False,\n",
       "  'V_tension': False,\n",
       "  'V_fails': False,\n",
       "  'V_hate': False,\n",
       "  'V_where': False,\n",
       "  'V_2002': False,\n",
       "  'V_difficult': False,\n",
       "  'V_try': False,\n",
       "  'V_sex': False,\n",
       "  'V_sequences': False,\n",
       "  'V_dry': False,\n",
       "  'V_sides': False,\n",
       "  'V_lock': False,\n",
       "  'V_frame': False,\n",
       "  'V_stunt': False,\n",
       "  'V_british': False,\n",
       "  'V_relationship': False,\n",
       "  'V_charming': False,\n",
       "  'V_soundtrack': False,\n",
       "  'V_gag': False,\n",
       "  'V_remake': False,\n",
       "  'V_emotions': False,\n",
       "  'V_remains': False,\n",
       "  'V_imagine': False,\n",
       "  'V_odd': False,\n",
       "  'V_business': False,\n",
       "  'V_plain': False,\n",
       "  'V_strength': False,\n",
       "  'V_until': False,\n",
       "  'V_delight': False,\n",
       "  'V_pleasures': False,\n",
       "  'V_theaters': False,\n",
       "  'V_adults': False,\n",
       "  'V_virtually': False,\n",
       "  'V_bitter': False,\n",
       "  'V_brown': False,\n",
       "  'V_talented': False,\n",
       "  'V_tired': False,\n",
       "  'V_entirely': False,\n",
       "  'V_exactly': False,\n",
       "  'V_beautifully': False,\n",
       "  'V_pretentious': False,\n",
       "  'V_share': False,\n",
       "  'V_robert': False,\n",
       "  'V_excellent': False,\n",
       "  'V_taking': False,\n",
       "  'V_manner': False,\n",
       "  'V_bears': False,\n",
       "  'V_tv': False,\n",
       "  'V_merely': False,\n",
       "  'V_clearly': False,\n",
       "  'V_complex': False,\n",
       "  'V_final': False,\n",
       "  'V_shots': False,\n",
       "  'V_deeper': False,\n",
       "  'V_personal': False,\n",
       "  'V_achievement': False,\n",
       "  'V_involved': False,\n",
       "  'V_hours': False,\n",
       "  'V_ones': False,\n",
       "  'V_reveals': False,\n",
       "  'V_emotionally': False,\n",
       "  'V_epic': False,\n",
       "  'V_effort': False,\n",
       "  'V_ugly': False,\n",
       "  'V_fantastic': False,\n",
       "  'V_complete': False,\n",
       "  'V_pat': False,\n",
       "  'V_however': False,\n",
       "  'V_across': False,\n",
       "  'V_convincing': False,\n",
       "  'V_mildly': False,\n",
       "  'V_creates': False,\n",
       "  'V_ideas': False,\n",
       "  'V_delivery': False,\n",
       "  'V_old-fashioned': False,\n",
       "  'V_ice': False,\n",
       "  'V_days': False,\n",
       "  'V_mediocre': False,\n",
       "  'V_start': False,\n",
       "  'V_tragic': False,\n",
       "  'V_fantasies': False,\n",
       "  'V_saturday': False,\n",
       "  'V_gone': False,\n",
       "  'V_run': False,\n",
       "  'V_foreign': False,\n",
       "  'V_sets': False,\n",
       "  'V_theatrical': False,\n",
       "  'V_changing': False,\n",
       "  'V_visually': False,\n",
       "  'V_hackneyed': False,\n",
       "  'V_problem': False,\n",
       "  'V_offensive': False,\n",
       "  'V_cult': False,\n",
       "  'V_favor': False,\n",
       "  'V_among': False,\n",
       "  'V_odds': False,\n",
       "  'V_skin': False,\n",
       "  'V_dream': False,\n",
       "  'V_america': False,\n",
       "  'V_protagonist': False,\n",
       "  'V_asks': False,\n",
       "  'V_hip': False,\n",
       "  'V_queen': False,\n",
       "  'V_delightful': False,\n",
       "  'V_air': False,\n",
       "  'V_finally': False,\n",
       "  'V_cool': False,\n",
       "  'V_future': False,\n",
       "  'V_actresses': False,\n",
       "  'V_condition': False,\n",
       "  'V_mindless': False,\n",
       "  'V_spielberg': False,\n",
       "  'V_writing': False,\n",
       "  'V_expectation': False,\n",
       "  'V_ride': False,\n",
       "  'V_beautiful': False,\n",
       "  'V_twists': False,\n",
       "  'V_nicely': False,\n",
       "  'V_someone': False,\n",
       "  'V_twice': False,\n",
       "  'V_cross': False,\n",
       "  'V_peter': False,\n",
       "  'V_whimsical': False,\n",
       "  'V_ritchie': False,\n",
       "  'V_smoking': False,\n",
       "  'V_barrels': False,\n",
       "  'V_murder': False,\n",
       "  'V_rock': False,\n",
       "  'V_course': False,\n",
       "  'V_middle': False,\n",
       "  'V_date': False,\n",
       "  'V_impossible': False,\n",
       "  'V_murphy': False,\n",
       "  'V_bizarre': False,\n",
       "  'V_directed': False,\n",
       "  'V_thousands': False,\n",
       "  'V_exhilarating': False,\n",
       "  'V_witness': False,\n",
       "  'V_purpose': False,\n",
       "  'V_holly': False,\n",
       "  'V_major': False,\n",
       "  'V_stylish': False,\n",
       "  'V_help': False,\n",
       "  'V_touching': False,\n",
       "  'V_cute': False,\n",
       "  'V_call': False,\n",
       "  'V_justice': False,\n",
       "  'V_considered': False,\n",
       "  'V_saw': False,\n",
       "  'V_actress': False,\n",
       "  'V_indians': False,\n",
       "  'V_pack': False,\n",
       "  'V_energetic': False,\n",
       "  'V_artistic': False,\n",
       "  'V_experiences': False,\n",
       "  'V_sensitive': False,\n",
       "  'V_school': False,\n",
       "  'V_brooklyn': False,\n",
       "  'V_form': False,\n",
       "  'V_indie': False,\n",
       "  'V_let': False,\n",
       "  'V_suspenseful': False,\n",
       "  'V_impressive': False,\n",
       "  'V_stage': False,\n",
       "  'V_substance': False,\n",
       "  'V_flawed': False,\n",
       "  'V_expected': False,\n",
       "  'V_head': False,\n",
       "  'V_bag': False,\n",
       "  'V_myself': False,\n",
       "  'V_artist': False,\n",
       "  'V_niro': False,\n",
       "  'V_unfocused': False,\n",
       "  'V_essentially': False,\n",
       "  'V_festival': False,\n",
       "  'V_begins': False,\n",
       "  'V_realized': False,\n",
       "  'V_shoot': False,\n",
       "  'V_usually': False,\n",
       "  'V_rush': False,\n",
       "  'V_green': False,\n",
       "  'V_10': False,\n",
       "  'V_rendered': False,\n",
       "  'V_situations': False,\n",
       "  'V_ends': False,\n",
       "  'V_george': False,\n",
       "  'V_awful': False,\n",
       "  'V_suffering': False,\n",
       "  'V_uses': False,\n",
       "  'V_bore': False,\n",
       "  'V_problems': False,\n",
       "  'V_finding': False,\n",
       "  'V_commercial': False,\n",
       "  'V_coming-of-age': False,\n",
       "  'V_first-rate': False,\n",
       "  'V_told': False,\n",
       "  'V_tom': False,\n",
       "  'V_female': False,\n",
       "  'V_falls': False,\n",
       "  'V_scary': False,\n",
       "  'V_forget': False,\n",
       "  'V_missing': False,\n",
       "  'V_issues': False,\n",
       "  'V_provocative': False,\n",
       "  'V_she': False,\n",
       "  'V_credits': False,\n",
       "  'V_document': False,\n",
       "  'V_equally': False,\n",
       "  'V_thin': False,\n",
       "  'V_whom': False,\n",
       "  'V_skill': False,\n",
       "  'V_nasty': False,\n",
       "  'V_able': False,\n",
       "  'V_satire': False,\n",
       "  'V_dragon': False,\n",
       "  'V_greatest': False,\n",
       "  'V_iranian': False,\n",
       "  'V_earth': False,\n",
       "  'V_humanity': True,\n",
       "  'V_class': False,\n",
       "  'V_cultural': False,\n",
       "  'V_noir': False,\n",
       "  'V_absolutely': False,\n",
       "  'V_chemistry': False,\n",
       "  'V_divine': False,\n",
       "  'V_terms': False,\n",
       "  'V_soon': False,\n",
       "  'V_ticket': False,\n",
       "  'V_fair': False,\n",
       "  'V_spiritual': False,\n",
       "  'V_genuinely': False,\n",
       "  'V_teens': False,\n",
       "  'V_although': False,\n",
       "  'V_fantasy': False,\n",
       "  'V_bland': False,\n",
       "  'V_enigma': False,\n",
       "  'V_screenwriter': False,\n",
       "  'V_families': False,\n",
       "  'V_apart': False,\n",
       "  'V_eloquent': False,\n",
       "  'V_meditation': False,\n",
       "  'V_scene': False,\n",
       "  'V_outrageous': False,\n",
       "  'V_potential': False,\n",
       "  'V_sappy': False,\n",
       "  'V_eric': False,\n",
       "  'V_already': False,\n",
       "  'V_tries': False,\n",
       "  'V_sequels': False,\n",
       "  'V_artists': False,\n",
       "  'V_sloppy': False,\n",
       "  'V_weird': False,\n",
       "  'V_intensity': False,\n",
       "  'V_value': False,\n",
       "  'V_store': False,\n",
       "  'V_warning': False,\n",
       "  'V_biting': False,\n",
       "  'V_storyline': False,\n",
       "  'V_above': False,\n",
       "  'V_anderson': False,\n",
       "  'V_sadly': False,\n",
       "  'V_animal': False,\n",
       "  'V_song': False,\n",
       "  'V_depressing': False,\n",
       "  'V_throws': False,\n",
       "  'V_touch': False,\n",
       "  'V_david': False,\n",
       "  'V_maybe': False,\n",
       "  'V_adolescent': False,\n",
       "  'V_number': False,\n",
       "  'V_beauty': False,\n",
       "  'V_team': False,\n",
       "  'V_catch': False,\n",
       "  'V_research': False,\n",
       "  'V_unflinching': False,\n",
       "  'V_combination': False,\n",
       "  'V_victims': False,\n",
       "  'V_yourself': False,\n",
       "  'V_straight': False,\n",
       "  'V_lines': False,\n",
       "  'V_thoughtful': False,\n",
       "  'V_dreary': False,\n",
       "  'V_central': False,\n",
       "  'V_surprise': False,\n",
       "  'V_spy': False,\n",
       "  'V_words': False,\n",
       "  'V_trappings': False,\n",
       "  'V_combines': False,\n",
       "  'V_drug': False,\n",
       "  'V_success': False,\n",
       "  'V_enthusiasm': False,\n",
       "  'V_slapstick': False,\n",
       "  'V_atmosphere': False,\n",
       "  'V_week': False,\n",
       "  'V_bottom': False,\n",
       "  'V_gosling': False,\n",
       "  'V_woo': False,\n",
       "  'V_places': False,\n",
       "  'V_appear': False,\n",
       "  'V_park': False,\n",
       "  'V_rhythm': False,\n",
       "  'V_rely': False,\n",
       "  'V_teenage': False,\n",
       "  'V_starts': False,\n",
       "  'V_possible': False,\n",
       "  'V_create': False,\n",
       "  'V_complicated': False,\n",
       "  'V_jackie': False,\n",
       "  'V_provide': False,\n",
       "  'V_degree': False,\n",
       "  'V_basic': False,\n",
       "  'V_proceedings': False,\n",
       "  'V_quest': False,\n",
       "  'V_disbelief': False,\n",
       "  'V_core': False,\n",
       "  ...},\n",
       " 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIWC_featuresets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-d0adf29684a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mLIWC_featuresets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLIWC_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLIWC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-87-d0adf29684a8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mLIWC_featuresets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLIWC_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLIWC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-86-9c11275f7bb5>\u001b[0m in \u001b[0;36mLIWC_features\u001b[1;34m(docs, word_features, LIWC)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mLIWC_words\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mLIWC\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLIWC\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'126'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[0mPos\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: tuple indices must be integers or slices, not list"
     ]
    }
   ],
   "source": [
    "LIWC_featuresets = [(LIWC_features(d, word_features, LIWC), c) for (d, c) in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain the classifier using these features\n",
    "train_set, test_set = LIWC_featuresets[1000:], LIWC_featuresets[:1000]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.523"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Kaggle train and test classifier ##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to read kaggle training file, train and test a classifier \n",
    "def processkaggle(dirPath,limitStr):\n",
    "  # convert the limit argument from a string to an int\n",
    "  limit = int(limitStr)\n",
    "  \n",
    "  os.chdir(dirPath)\n",
    "  \n",
    "  f = open('./train.tsv', 'r')\n",
    "  # loop over lines in the file and use the first limit of them\n",
    "  phrasedata = []\n",
    "  for line in f:\n",
    "    # ignore the first line starting with Phrase and read all lines\n",
    "    if (not line.startswith('Phrase')):\n",
    "      # remove final end of line character\n",
    "      line = line.strip()\n",
    "      # each line has 4 items separated by tabs\n",
    "      # ignore the phrase and sentence ids, and keep the phrase and sentiment\n",
    "      phrasedata.append(line.split('\\t')[2:4])\n",
    "  \n",
    "  # pick a random sample of length limit because of phrase overlapping sequences\n",
    "  random.shuffle(phrasedata)\n",
    "  phraselist = phrasedata[:limit]\n",
    "\n",
    "  print('Read', len(phrasedata), 'phrases, using', len(phraselist), 'random phrases')\n",
    "  \n",
    "  # create list of phrase documents as (list of words, label)\n",
    "  phrasedocs = []\n",
    "  # add all the phrases\n",
    "\n",
    "  # each phrase has a list of tokens and the sentiment label (from 0 to 4)\n",
    "  ### bin to only 3 categories for better performance\n",
    "  for phrase in phraselist:\n",
    "    tokens = nltk.word_tokenize(phrase[0])\n",
    "    phrasedocs.append((tokens, int(phrase[1])))\n",
    "\n",
    "  # possibly filter tokens\n",
    "  # lowercase - each phrase is a pair consisting of a token list and a label\n",
    "  docs = []\n",
    "  for phrase in phrasedocs:\n",
    "    lowerphrase = ([w.lower() for w in phrase[0]], phrase[1])\n",
    "    docs.append (lowerphrase)\n",
    "  # print a few\n",
    "  for phrase in docs[:10]:\n",
    "    print (phrase)\n",
    "\n",
    "  # continue as usual to get all words and create word features\n",
    "  all_words_list = [word for (sent,cat) in docs for word in sent]\n",
    "  all_words = nltk.FreqDist(all_words_list)\n",
    "  print(len(all_words))\n",
    "\n",
    "  # get the 1500 most frequently appearing keywords in the corpus\n",
    "  word_items = all_words.most_common(1500)\n",
    "  word_features = [word for (word,count) in word_items]\n",
    "\n",
    "  # feature sets from a feature definition function\n",
    "  featuresets = [(document_features(d, word_features), c) for (d, c) in docs]\n",
    "\n",
    "  path = \"/Users/hub20/subjclueslen1-HLTEMNLP05.tff\"\n",
    "  SL = readSubjectivity(path)\n",
    "  \n",
    "  SL_featuresets = [(SL_features(d, word_features, SL), c) for (d, c) in docs]\n",
    "\n",
    "  train_set, test_set = SL_featuresets[1000:], SL_featuresets[:1000]\n",
    "  classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "  nltk.classify.accuracy(classifier, test_set)\n",
    "\n",
    "  # perform the cross-validation on the featuresets with word features and generate accuracy\n",
    "  num_folds = 10\n",
    "  cross_validation_accuracy(num_folds, SL_featuresets)\n",
    "\n",
    "  ## other evaluation measures:  confusion matrix, precision, recall, F1 ##\n",
    "\n",
    "  goldlist = []\n",
    "  predictedlist = []\n",
    "  for (features, label) in test_set:\n",
    "    \tgoldlist.append(label)\n",
    "    \tpredictedlist.append(classifier.classify(features))\n",
    "        \n",
    "  cm = nltk.ConfusionMatrix(goldlist, predictedlist)\n",
    "  print(cm.pretty_format(sort_by_count=True, truncate=9))\n",
    "\n",
    "  # or show the results as percentages\n",
    "  print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))\n",
    "\n",
    "  # call the function with our data\n",
    "  eval_measures(goldlist, predictedlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uses the SL featuresets as a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncommandline interface takes a directory name with kaggle subdirectory for train.tsv\\n   and a limit to the number of kaggle phrases to use\\nIt then processes the files and trains a kaggle movie review sentiment classifier.\\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "commandline interface takes a directory name with kaggle subdirectory for train.tsv\n",
    "   and a limit to the number of kaggle phrases to use\n",
    "It then processes the files and trains a kaggle movie review sentiment classifier.\n",
    "\n",
    "python classifyKaggle.py corpus/ 3\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
